{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy, os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../Share/')\n",
    "sys.path.append('../../Share/Manual_processing/')\n",
    "import baseline, config, Model, utils, Same_with_MATLAB, Feature_info\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def restore_labels(mat, labels_windowed):\n",
    "\n",
    "    original_length = mat['Data_ADC'].shape[1]\n",
    "    win_size = 600 #Original\n",
    "    win_step = 120\n",
    "    valid_length = original_length - 2 * 60\n",
    "\n",
    "    label_full = np.zeros(original_length, dtype=labels_windowed.dtype) # 복원될 시계열 레이블 (원본 길이)\n",
    "\n",
    "    # 슬라이딩 윈도우 인덱스 따라 레이블 채워넣기\n",
    "    for i, label in enumerate(labels_windowed):\n",
    "        start = 60 + i * win_step\n",
    "        end = start + win_size\n",
    "        if end <= original_length - 60:\n",
    "            label_full[start:end] = label\n",
    "\n",
    "    return label_full\n",
    "\n",
    "\n",
    "def filtering_zero(X, y, erase_label):\n",
    "    # 1. erase_label 제거\n",
    "    keep_indices = y != erase_label\n",
    "    X = X[keep_indices]\n",
    "    y = y[keep_indices]\n",
    "\n",
    "    # 2. erase_label보다 큰 값은 1씩 감소\n",
    "    y = np.where(y > erase_label, y - 1, y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def vis_graph(history):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def heatmap_confusion_matrix(X_test, y_test, model):\n",
    "    # Predict class labels on the test set\n",
    "    y_pred_probs = model.predict(X_test, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)  # convert softmax probs to predicted class\n",
    "    y_true = y_test\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(np.max(y_test)+1), yticklabels=range(np.max(y_test)+1))\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def balance_data(X, y):\n",
    "    # Count samples per class\n",
    "    class_counts = Counter(y)\n",
    "    min_count = min(class_counts.values())  # target: balance all to minority count\n",
    "\n",
    "    indices_list = []\n",
    "\n",
    "    for label in sorted(class_counts.keys()):\n",
    "        label_indices = np.where(y == label)[0]\n",
    "        selected_indices = np.random.choice(label_indices, size=min_count, replace=False)\n",
    "        indices_list.extend(selected_indices)\n",
    "\n",
    "    # Shuffle all selected indices\n",
    "    balanced_indices = np.random.permutation(indices_list)\n",
    "\n",
    "    # Subset the data\n",
    "    X_balanced = X[balanced_indices]\n",
    "    y_balanced = y[balanced_indices]\n",
    "\n",
    "    return X_balanced, y_balanced"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def return_X_y(path, balance):\n",
    "    fs, lower_cutoff, upper_cutoff = Feature_info.fs, Feature_info.lower_cutoff, Feature_info.upper_cutoff\n",
    "    # fs, lower_cutoff, upper_cutoff = Feature_info.fs, 1, 300\n",
    "    filter_b, filter_a = Same_with_MATLAB.cheby2(4, 30, [lower_cutoff / (fs/2), upper_cutoff / (fs/2)], btype='bandpass')\n",
    "\n",
    "    data_per_class_files = os.listdir(path)\n",
    "    X, y = [], []\n",
    "\n",
    "    for cls in data_per_class_files:\n",
    "        input_path = path+cls+'/'\n",
    "        files = os.listdir(input_path)\n",
    "        mat = scipy.io.loadmat(input_path+files[0])\n",
    "        label = mat['Data_Cls'].reshape(-1)  # shape: (1, 1729)\n",
    "\n",
    "        feat_mean = np.tile(Feature_info.feat_mean_lst, (4, 1))\n",
    "        feat_std = np.tile(Feature_info.feat_std_lst, (4, 1))\n",
    "\n",
    "        mapped_label = np.where(label == 0, 0, int(cls))\n",
    "        restored_label = restore_labels(mat, mapped_label)\n",
    "\n",
    "        #print(mat['Data_ADC'].shape, mat['Data_Cls'].shape, restored_label.shape)\n",
    "        extractor = Same_with_MATLAB.EMGFeatureExtractor(feat_mean, feat_std, filter_b, filter_a, Norm_bool=True, num_feature_set=14) #I tried 23, but not so good\n",
    "        extractor.buffer = mat['Data_ADC']\n",
    "        #1000, 50 = winsize and winstep\n",
    "        features, labels = extractor.extract_features_with_labels(win_size=1000, win_step=50, feat_exclude=25, filtering=False, restored_label=restored_label)\n",
    "\n",
    "        features = np.transpose(features, (2, 0, 1))  # shape: (1729, 4, 14)\n",
    "        X.append(features)\n",
    "        y.append(labels)\n",
    "        #print(features.shape, labels.shape)\n",
    "\n",
    "    X_train = np.concatenate(X, axis=0)\n",
    "    y_train = np.concatenate(y, axis=0)\n",
    "    X_train = X_train[:, :, :, np.newaxis]\n",
    "    #print(pd.Series(y_train).value_counts())\n",
    "    print(X_train.shape, y_train.shape)\n",
    "\n",
    "    if balance:\n",
    "        X_train, y_train = balance_data(X_train, y_train)\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "\n",
    "def train_model_feature_wise(X_train, y_train, X_test, y_test):\n",
    "    X_train, y_train = filtering_zero(X_train, y_train, erase_label=0)\n",
    "    X_test, y_test = filtering_zero(X_test, y_test, erase_label=0)\n",
    "    ACC_lst = []\n",
    "\n",
    "    for feature_idx in [2, 10]:\n",
    "        One_X_train = X_train[:, :, feature_idx, :]\n",
    "        One_X_test = X_test[:, :, feature_idx, :]\n",
    "\n",
    "        model = Model.Original_model_1DCNN(One_X_train.shape[1:], num_class=np.max(y_train)+1)\n",
    "\n",
    "        history, model = Model.Train_model(\n",
    "            model, One_X_train, y_train, One_X_test, y_test,\n",
    "            set_epoch=200, set_batch_size=256, Model_name='V0',\n",
    "            set_verbose=False, save_model_set=False\n",
    "        )\n",
    "        ACC_lst.append(np.max(history.history['val_accuracy']))\n",
    "        #vis_graph(history)\n",
    "        #print(\"\\n\\n\")\n",
    "        #heatmap_confusion_matrix(One_X_test, y_test, model)\n",
    "\n",
    "def train_model(X_train, y_train, X_test, y_test, heatmap_bool=False):\n",
    "    X_train, y_train = filtering_zero(X_train, y_train, erase_label=0)\n",
    "    X_test, y_test = filtering_zero(X_test, y_test, erase_label=0)\n",
    "\n",
    "    model = Model.Original_model(X_train.shape[1:], num_class=np.max(y_train)+1)\n",
    "\n",
    "    history, model = Model.Train_model(\n",
    "        model, X_train, y_train, X_test, y_test,\n",
    "        set_epoch=100, set_batch_size=256, Model_name='V0',\n",
    "        set_verbose=False, save_model_set=False\n",
    "    )\n",
    "    vis_graph(history)\n",
    "    if heatmap_bool:\n",
    "        heatmap_confusion_matrix(X_test, y_test, model)\n",
    "\n",
    "def run(subject, modality):\n",
    "    if modality == 'EMG': bluetooth_id = 'E8DD80E550BB'\n",
    "    elif modality == 'ENG': bluetooth_id = 'E9AD0E7DCC2B'\n",
    "    else:\n",
    "        print(\"Modality should be EMG or ENG\")\n",
    "        return\n",
    "\n",
    "    X_train, y_train = return_X_y(path = base_path+f'{subject}/{modality}_v1/{bluetooth_id}/raw/', balance=True)\n",
    "    X_test, y_test = return_X_y(path = base_path+f'{subject}/{modality}_v2/{bluetooth_id}/raw/', balance=True)\n",
    "    train_model(X_train, y_train, X_test, y_test, heatmap_bool=False)\n",
    "\n",
    "    X_train, y_train = return_X_y(path = base_path+f'{subject}/{modality}_v2/{bluetooth_id}/raw/', balance=True)\n",
    "    X_test, y_test = return_X_y(path = base_path+f'{subject}/{modality}_v1/{bluetooth_id}/raw/', balance=True)\n",
    "    train_model(X_train, y_train, X_test, y_test, heatmap_bool=False)"
   ],
   "id": "b559a00097f2b37a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "base_path = 'C:/Users/hml76/PycharmProjects/MindForce/data/EMG_ENG/'",
   "id": "753498be52d2485b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run(subject='Hunmin', modality='EMG')",
   "id": "84d3bf077619e7b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run(subject='Hunmin', modality='ENG')",
   "id": "43710600b2754252",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Byeongchan",
   "id": "365b1a1ae3b8ce94"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run(subject='Byeongchan', modality='EMG')",
   "id": "cf0f741fdc83df2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run(subject='Byeongchan', modality='ENG')",
   "id": "785329f0518bf2c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "706ea5829c5a9ee9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run(subject='Hongjun', modality='EMG')",
   "id": "b60ff560078180e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run(subject='Hongjun', modality='ENG')",
   "id": "cf72c6037af20b64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "afc1693ced693195",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run(subject='Jongin', modality='EMG')",
   "id": "aaedeee3ffb5a9b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run(subject='Jongin', modality='ENG')",
   "id": "e69f9600123b8fd8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "17b44b256939bcbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "98e4e3ad86678546",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run(subject='Youngchul', modality='EMG')",
   "id": "fbb8e70b7958a907",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run(subject='Youngchul', modality='ENG')",
   "id": "b59cdaf5b1503359",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4c60024f7fd65bb1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run(subject='Harold', modality='EMG')",
   "id": "cca72bfd54c1c19f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run(subject='Harold', modality='ENG')",
   "id": "344dba6b4657c0e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "70e65c93f95e56db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7b7742b6f7dc34f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run(subject='Carlson', modality='EMG')",
   "id": "8298f2892e26ce39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run(subject='Carlson', modality='ENG')",
   "id": "f9cd31a1bb2f0b0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run(subject='Minjeong', modality='EMG')",
   "id": "130e5e1284786d5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run(subject='Minjeong', modality='ENG')",
   "id": "db307e2a2f1130f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6df49df920b71036",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
