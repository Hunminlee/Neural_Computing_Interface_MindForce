{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T19:05:17.728359Z",
     "start_time": "2025-07-01T19:05:17.515203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import config\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "id": "d97a4eda5c0ae2da",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Baseline: Training datasets and store\n",
    "- Time 1 (1 day)\n",
    "- Time 10 (3 days)\n",
    "- Time 14 (4 days)\n",
    "- Time 18 (5 days)\n",
    "- Time 22 (6 days)"
   ],
   "id": "1450ab5a6650964"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-01T18:33:35.920492Z",
     "start_time": "2025-07-01T18:32:37.218360Z"
    }
   },
   "source": [
    "'''import Test_without_Training\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for K in [1, 4, 8]:\n",
    "        trainer = Test_without_Training.TremorModelTrainer(config, subject=\"Xianyu\")\n",
    "        trainer.run_all_sessions_training_K_data(K)\n",
    "        df = trainer.save_results(f'../Results/Baseline_results_train_with_{K}data_X.csv')\n",
    "# 저장해놨어서 데이터 업데이트 전에 한번 돌리면 굳이 안돌려도 됨'''"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1/10 - Session Exp_2025-06-24-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "(8521, 4, 14, 1) (8521,)\n",
      "Dataset 2/10 - Session Exp_2025-06-24-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is saved)\n",
      "Maximum training accuracy : 86.42%\n",
      "Maximum validation accuracy : 88.37%\n",
      "Accuracy of test dataset using model V0: 87.2093%\n",
      "Dataset 3/10 - Session Exp_2025-06-26-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 78.7191%\n",
      "Dataset 4/10 - Session Exp_2025-06-26-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 49.9415%\n",
      "Dataset 5/10 - Session Exp_2025-06-27-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "There is more than one dataset - check\n",
      "Accuracy on unseen dataset: 75.1719%\n",
      "Dataset 6/10 - Session Exp_2025-06-27-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 71.5880%\n",
      "Dataset 7/10 - Session Exp_2025-06-30-v1/FEFFF6FFF5FF/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 88.0237%\n",
      "Dataset 8/10 - Session Exp_2025-06-30-v2/FEFFF6FFF5FF/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 55.8491%\n",
      "Dataset 9/10 - Session Exp_2025-07-01-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 64.6002%\n",
      "Dataset 10/10 - Session Exp_2025-07-01-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 77.3712%\n",
      "Results saved to ../Results/Baseline_results_train_with_1data_X.csv\n",
      "\n",
      "\n",
      "Dataset 1/10 - Session Exp_2025-06-24-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "(8521, 4, 14, 1) (8521,)\n",
      "Dataset 2/10 - Session Exp_2025-06-24-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "(16883, 4, 14, 1) (16883,)\n",
      "Dataset 3/10 - Session Exp_2025-06-26-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "(25215, 4, 14, 1) (25215,)\n",
      "Dataset 4/10 - Session Exp_2025-06-26-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "(33674, 4, 14, 1) (33674,)\n",
      "Dataset 5/10 - Session Exp_2025-06-27-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is saved)\n",
      "Maximum training accuracy : 77.59%\n",
      "Maximum validation accuracy : 84.37%\n",
      "Accuracy of test dataset using model V0: 83.4808%\n",
      "Dataset 6/10 - Session Exp_2025-06-27-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 61.5172%\n",
      "Dataset 7/10 - Session Exp_2025-06-30-v1/FEFFF6FFF5FF/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 88.4647%\n",
      "Dataset 8/10 - Session Exp_2025-06-30-v2/FEFFF6FFF5FF/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 54.3042%\n",
      "Dataset 9/10 - Session Exp_2025-07-01-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 62.4913%\n",
      "Dataset 10/10 - Session Exp_2025-07-01-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 78.0892%\n",
      "Results saved to ../Results/Baseline_results_train_with_4data_X.csv\n",
      "\n",
      "\n",
      "Dataset 1/10 - Session Exp_2025-06-24-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "(8521, 4, 14, 1) (8521,)\n",
      "Dataset 2/10 - Session Exp_2025-06-24-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "(16883, 4, 14, 1) (16883,)\n",
      "Dataset 3/10 - Session Exp_2025-06-26-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "(25215, 4, 14, 1) (25215,)\n",
      "Dataset 4/10 - Session Exp_2025-06-26-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "(33674, 4, 14, 1) (33674,)\n",
      "Dataset 5/10 - Session Exp_2025-06-27-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "There is more than one dataset - check\n",
      "(42171, 4, 14, 1) (42171,)\n",
      "Dataset 6/10 - Session Exp_2025-06-27-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "(50419, 4, 14, 1) (50419,)\n",
      "Dataset 7/10 - Session Exp_2025-06-30-v1/FEFFF6FFF5FF/\n",
      "========================================\n",
      "(58950, 4, 14, 1) (58950,)\n",
      "Dataset 8/10 - Session Exp_2025-06-30-v2/FEFFF6FFF5FF/\n",
      "========================================\n",
      "(67345, 4, 14, 1) (67345,)\n",
      "Dataset 9/10 - Session Exp_2025-07-01-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is saved)\n",
      "Maximum training accuracy : 78.18%\n",
      "Maximum validation accuracy : 80.12%\n",
      "Accuracy of test dataset using model V0: 79.8233%\n",
      "Dataset 10/10 - Session Exp_2025-07-01-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 77.7649%\n",
      "Results saved to ../Results/Baseline_results_train_with_8data_X.csv\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T19:05:30.311597Z",
     "start_time": "2025-07-01T19:05:30.307933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "b_path = 'C:/Users/hml76/PycharmProjects/Tremor_project_local/NCI_mindforce'\n",
    "baseline_K = ['1', '4', '8']\n",
    "baselines = []\n",
    "\n",
    "for idx, K in enumerate(baseline_K):\n",
    "    baselines.append(b_path + f'/github/Results/Baseline_results_train_with_{K}data_X.csv')\n",
    "\n",
    "SUBJECT = \"Xianyu\""
   ],
   "id": "f0904e457a7efa1c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Training from scratch in every data\n",
    "- Performance should be high\n",
    "- Objective"
   ],
   "id": "617e3524e555e3bc"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-01T19:05:32.889838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import Training_from_scratch\n",
    "\n",
    "prog_trainer = Training_from_scratch.ProgressiveTrainer(config, subject=SUBJECT)\n",
    "Init_acc_all, Prev_acc_all, Trained_acc_all = prog_trainer.run(plot_learning_curve=False)\n",
    "prog_trainer.plot_results(baselines, baseline_K)\n",
    "\n",
    "for idx, x in enumerate([Init_acc_all, Prev_acc_all, Trained_acc_all]):\n",
    "    if idx==0:\n",
    "        print(f\"Average of acc without training anything (should be random): {np.mean(x)*100:.2f}%\")\n",
    "    elif idx==1:\n",
    "        print(f\"Average of acc using previous test data after training: {np.mean(x)*100:.2f}%\")\n",
    "    elif idx==2:\n",
    "        print(f\"Average of acc using current test data after training: {np.mean(x)*100:.2f}%\")\n",
    "for idx, b in enumerate(baselines):\n",
    "    print(f\"Baseline K-{baseline_K[idx]}: {float(np.mean(pd.read_csv(baselines[idx])['Accuracy'][int(baseline_K[idx]):])):.2f}%\")"
   ],
   "id": "c78761ed10a16497",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================\n",
      "Dataset 1/10 - Session Exp_2025-06-24-v1/E9AD0E7DCC2B/\n",
      "===========================================\n",
      "Start Training (total epochs: 50)...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Transfer Learning - Incremental : Model is cumulatively updated",
   "id": "1cbeceb6c96dfa57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import Transfer_Learning\n",
    "\n",
    "tl_trainer = Transfer_Learning.TransferLearningTrainer(config, subject=SUBJECT, increment_true_false=\"True\")\n",
    "Init_acc_all, Prev_acc_all, Trained_acc_all = tl_trainer.run(plot_learning_curve=False)   #True if want to see convergence for each session round\n",
    "tl_trainer.plot_results(baselines, baseline_K)\n",
    "\n",
    "for idx, x in enumerate([Init_acc_all, Prev_acc_all, Trained_acc_all]):\n",
    "    if idx==0:\n",
    "        print(f\"Average of acc without training this data (init; unseen) - incrementally trained model with previous datasets: {np.mean(x)*100:.2f}%\")\n",
    "    elif idx==1:\n",
    "        print(f\"Average of acc using previous test data after training (with increment): {np.mean(x)*100:.2f}%\")\n",
    "    elif idx==2:\n",
    "        print(f\"Average of acc using current test data after training (with increment): {np.mean(x)*100:.2f}%\")\n",
    "\n",
    "for idx, b in enumerate(baselines):\n",
    "    print(f\"Baseline K-{baseline_K[idx]}: {float(np.mean(pd.read_csv(baselines[idx])['Accuracy'][int(baseline_K[idx]):])):.2f}%\")"
   ],
   "id": "b04b8081ae41aa29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Few-shot Learning (MAML) adaptation",
   "id": "495b33d36f8abc55"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import Few_shot_Learning\n",
    "\n",
    "trainer = Few_shot_Learning.MAMLProgressiveTrainer(config, subject=SUBJECT, K_shot=10, query_size=100)\n",
    "Init_acc_all, Prev_acc_all, Trained_acc_all = trainer.run()\n",
    "trainer.plot_results(baselines, baseline_K)\n",
    "\n",
    "for idx, x in enumerate([Init_acc_all, Prev_acc_all, Trained_acc_all]):\n",
    "    if idx==0:\n",
    "        print(f\"Average of acc without training anything (should be random): {np.mean(x)*100:.2f}%\")\n",
    "    elif idx==1:\n",
    "        print(f\"Average of acc using previous test data after training: {np.mean(x)*100:.2f}%\")\n",
    "    elif idx==2:\n",
    "        print(f\"Average of acc using current test data after training: {np.mean(x)*100:.2f}%\")\n",
    "\n",
    "for idx, b in enumerate(baselines):\n",
    "    print(f\"Baseline K-{baseline_K[idx]}: {float(np.mean(pd.read_csv(baselines[idx])['Accuracy'][int(baseline_K[idx]):])):.2f}%\")"
   ],
   "id": "ff3564540412d3a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Continual Learning (EWC)",
   "id": "c64b1204d953f165"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import Continual_Learning_EWC_\n",
    "\n",
    "cl_trainer = Continual_Learning_EWC_.ContinualLearningTrainer(config, subject=SUBJECT)\n",
    "Init_acc_all, Prev_acc_all, Trained_acc_all = cl_trainer.run()\n",
    "cl_trainer.plot_results(baselines, baseline_K)\n",
    "\n",
    "for idx, x in enumerate([Init_acc_all, Prev_acc_all, Trained_acc_all]):\n",
    "    if idx==0:\n",
    "        print(f\"Average of acc without training this data (init; unseen): {np.mean(x)*100:.2f}%\")\n",
    "    elif idx==1:\n",
    "        print(f\"Average of acc using previous test data after training: {np.mean(x)*100:.2f}%\")\n",
    "    elif idx==2:\n",
    "        print(f\"Average of acc using current test data after training: {np.mean(x)*100:.2f}%\")\n",
    "\n",
    "for idx, b in enumerate(baselines):\n",
    "    print(f\"Baseline K-{baseline_K[idx]}: {float(np.mean(pd.read_csv(baselines[idx])['Accuracy'][int(baseline_K[idx]):])):.2f}%\")"
   ],
   "id": "4ea332f22dc718fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fdc745341966397d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
