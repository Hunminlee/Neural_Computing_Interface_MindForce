{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:28:33.520643Z",
     "start_time": "2025-08-22T18:28:33.509413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.append('../../Share/')\n",
    "import Model\n",
    "\n",
    "def random_downsample_Num(X, y=None, n_keep=None, random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    if n_keep is None or n_keep > n_samples:\n",
    "        raise ValueError(f\"n_keep must be between 1 and {n_samples}, got {n_keep}\")\n",
    "\n",
    "    idx_keep = np.random.choice(n_samples, size=n_keep, replace=False)\n",
    "    X_down = X[idx_keep]\n",
    "\n",
    "    if y is not None:\n",
    "        y_down = y[idx_keep]\n",
    "        return X_down, y_down\n",
    "    else:\n",
    "        return X_down\n",
    "\n",
    "# Baseline training on subjects\n",
    "def feature_analysis(X_lst, y_lst):\n",
    "    num_trials = len(X_lst)\n",
    "    all_acc = []\n",
    "    for t in range(num_trials):\n",
    "        X, y = X_lst[t].reshape(-1,16,14,1), y_lst[t]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "        feature_set = 14\n",
    "        feat_acc = []\n",
    "\n",
    "        for f in range(feature_set):\n",
    "            X_train_f = X_train[:,:,f,:]\n",
    "            X_test_f = X_test[:,:,f,:]\n",
    "            #model = Model.Original_model(input_shape=X_train.shape[1:], num_class=6)\n",
    "            model = Model.Original_model_1DCNN(input_size=X_train_f.shape[1:], num_class=6)\n",
    "\n",
    "            history, _ = Model.Train_model(model, X_train_f, y_train, X_test_f, y_test, set_epoch=50, set_batch_size=128, Model_name=None, set_verbose=False, save_model_set=False)\n",
    "            #plt.plot(history.history['val_accuracy'])\n",
    "            #plt.plot(history.history['accuracy'])\n",
    "            #plt.show()\n",
    "\n",
    "            print(f\"\\tTrial {t+1}/{num_trials}/feat{f} | Val Acc: {np.max(history.history['val_accuracy'])}\")\n",
    "            feat_acc.append(np.max(history.history['val_accuracy']))\n",
    "        all_acc.append(feat_acc)\n",
    "\n",
    "    return all_acc\n",
    "\n",
    "\n",
    "def baseline_run(X_lst, y_lst):\n",
    "    num_trials, all_acc_per_session = len(X_lst), []\n",
    "    feature_set, num_channels = 14, 16\n",
    "\n",
    "    for t in range(num_trials):\n",
    "        X, y = X_lst[t].reshape(-1,num_channels,feature_set,1), y_lst[t]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "        model = Model.Original_model(input_shape=X_train.shape[1:], num_class=6)\n",
    "        history, _ = Model.Train_model(model, X_train, y_train, X_test, y_test, set_epoch=50, set_batch_size=128, Model_name=None, set_verbose=False, save_model_set=False)\n",
    "\n",
    "        print(f\"\\tTrial {t+1}/{num_trials} | Val Acc: {np.max(history.history['val_accuracy'])}\")\n",
    "        all_acc_per_session.append(np.max(history.history['val_accuracy']))\n",
    "\n",
    "    return all_acc_per_session\n",
    "\n",
    "\n",
    "def baseline_run_specific_T(X_lst, y_lst, trials):\n",
    "    all_acc_per_session = []\n",
    "    feature_set, num_channels = 14, 16\n",
    "\n",
    "    for t in trials:\n",
    "        X, y = X_lst[t].reshape(-1,num_channels,feature_set,1), y_lst[t]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "        model = Model.Original_model(input_shape=X_train.shape[1:], num_class=6)\n",
    "        history, _ = Model.Train_model(model, X_train, y_train, X_test, y_test, set_epoch=50, set_batch_size=128, Model_name=None, set_verbose=False, save_model_set=False)\n",
    "\n",
    "        print(f\"\\tTrial {t+1}/ | Val Acc: {np.max(history.history['val_accuracy'])}\")\n",
    "        all_acc_per_session.append(np.max(history.history['val_accuracy']))\n",
    "\n",
    "    return all_acc_per_session\n",
    "\n",
    "\n",
    "def baseline_run_specific_T_with_one_feature(X_lst, y_lst, trials, f=2):\n",
    "    all_acc_per_session = []\n",
    "    feature_set, num_channels = 14, 16\n",
    "\n",
    "    for t in trials:\n",
    "        X, y = X_lst[t].reshape(-1,num_channels,feature_set,1), y_lst[t]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "        X_train, X_test = X_train[:,:,f,:], X_test[:,:,f,:]\n",
    "\n",
    "        model = Model.Original_model_1DCNN(input_size=X_train.shape[1:], num_class=6)\n",
    "        history, _ = Model.Train_model(model, X_train, y_train, X_test, y_test, set_epoch=50, set_batch_size=128, Model_name=None, set_verbose=False, save_model_set=False)\n",
    "\n",
    "        print(f\"\\tTrial {t+1}/ | Val Acc: {np.max(history.history['val_accuracy'])}\")\n",
    "        all_acc_per_session.append(np.max(history.history['val_accuracy']))\n",
    "\n",
    "    return all_acc_per_session\n",
    "\n",
    "\n",
    "def inter_session_run(X_lst, y_lst):\n",
    "    num_trials = len(X_lst)\n",
    "    all_acc_K = []\n",
    "\n",
    "    for t in [1, 4, 7, 9]:\n",
    "        X_train = [X_lst[i].reshape(-1, 16, 14, 1) for i in range(t)]\n",
    "        X_train = np.concatenate(X_train, axis=0)\n",
    "        y_train = [y_lst[i] for i in range(t)]\n",
    "        y_train = np.concatenate(y_train, axis=0)\n",
    "\n",
    "        X_test = [X_lst[i].reshape(-1, 16, 14, 1) for i in range(t, len(X_lst))]\n",
    "        X_test = np.concatenate(X_test, axis=0)\n",
    "\n",
    "        y_test = [y_lst[i] for i in range(t, len(y_lst))]\n",
    "        y_test = np.concatenate(y_test, axis=0)\n",
    "        X_test, y_test = random_downsample_Num(X_test, y_test, n_keep=1000, random_state=42)\n",
    "        print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "        model = Model.Original_model(input_shape=X_train.shape[1:], num_class=6)\n",
    "        history, _ = Model.Train_model(model, X_train, y_train, X_test, y_test, set_epoch=50, set_batch_size=128, Model_name=None, set_verbose=False, save_model_set=False)\n",
    "\n",
    "        print(f\"\\tTrial {t+1}/{num_trials}/feat{f} | Val Acc: {np.max(history.history['val_accuracy'])}\")\n",
    "        all_acc_K.append(np.max(history.history['val_accuracy']))\n",
    "    return all_acc_K"
   ],
   "id": "f8f65a37150ac35b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Subject 1 버리기 + use only subject 2 and 3",
   "id": "eb849917a5e96f01"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-22T17:31:42.132768Z",
     "start_time": "2025-08-22T17:31:36.493515Z"
    }
   },
   "source": [
    "path = 'C:/Users/hml76/Desktop/Jupyter/Federated Prototype Learning/Dataset/Ours_cleaned/'\n",
    "fname = os.listdir(path)\n",
    "\n",
    "subjects = {\n",
    "    \"subject1\": {\"X\": [], \"Y\": []},\n",
    "    \"subject2\": {\"X\": [], \"Y\": []},\n",
    "    \"subject3\": {\"X\": [], \"Y\": []},\n",
    "}\n",
    "\n",
    "for f in fname:\n",
    "    for i in range(10):\n",
    "        X = np.array(pd.read_csv(path + f'{f}/rep{i}_X.csv'))\n",
    "        y = np.array(pd.read_csv(path + f'{f}/rep{i}_Y.csv'))\n",
    "\n",
    "        # shuffle\n",
    "        #indices = np.random.permutation(len(X))\n",
    "        #X, y = X[indices], y[indices]\n",
    "\n",
    "        # convert one-hot to integer labels\n",
    "        y_int = np.argmax(y, axis=1)\n",
    "        num_classes = np.max(y_int) + 1\n",
    "\n",
    "        # example rule to assign data to subject dict\n",
    "        if \"subject1\" in f:\n",
    "            subjects[\"subject1\"][\"X\"].append(X)\n",
    "            subjects[\"subject1\"][\"Y\"].append(y_int)\n",
    "        elif \"subject2\" in f:\n",
    "            subjects[\"subject2\"][\"X\"].append(X)\n",
    "            subjects[\"subject2\"][\"Y\"].append(y_int)\n",
    "        elif \"subject3\" in f:\n",
    "            subjects[\"subject3\"][\"X\"].append(X)\n",
    "            subjects[\"subject3\"][\"Y\"].append(y_int)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. K1/4/7/10 initialization (저걸로 학습시키기) + Test on rest of the subjects\n",
    "2."
   ],
   "id": "179a82d9c9168406"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Baseline - S2, S3",
   "id": "edc2f3b06854b888"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_lst2, y_lst2 = subjects[\"subject2\"][\"X\"], subjects[\"subject2\"][\"Y\"]\n",
    "X_lst3, y_lst3 = subjects[\"subject3\"][\"X\"], subjects[\"subject3\"][\"Y\"]\n",
    "\n",
    "S2_baseline = baseline_run(X_lst2, y_lst2)\n",
    "S3_baseline = baseline_run(X_lst3, y_lst3)"
   ],
   "id": "510b3d018f446715",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "S2_baseline_Ts = baseline_run_specific_T(X_lst2, y_lst2, [1,4,7,9])\n",
    "S3_baseline_Ts = baseline_run_specific_T(X_lst3, y_lst3, [1,4,7,9])"
   ],
   "id": "69c53ca93779193c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:29:42.056975Z",
     "start_time": "2025-08-22T18:28:36.925607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "S2_baseline_Ts_f = baseline_run_specific_T_with_one_feature(X_lst2, y_lst2, [1,4,7], f=2)\n",
    "S3_baseline_Ts_f = baseline_run_specific_T_with_one_feature(X_lst3, y_lst3, [1,4,7], f=2)"
   ],
   "id": "a596170ce7accfc5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 48.93%\n",
      "Maximum validation accuracy : 58.98%\n",
      "\tTrial 2/ | Val Acc: 0.5897821187973022\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 70.46%\n",
      "Maximum validation accuracy : 78.15%\n",
      "\tTrial 5/ | Val Acc: 0.78152996301651\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 44.96%\n",
      "Maximum validation accuracy : 50.57%\n",
      "\tTrial 8/ | Val Acc: 0.5057008862495422\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 61.69%\n",
      "Maximum validation accuracy : 69.04%\n",
      "\tTrial 2/ | Val Acc: 0.6903553009033203\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 37.58%\n",
      "Maximum validation accuracy : 45.35%\n",
      "\tTrial 5/ | Val Acc: 0.4534534513950348\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 54.32%\n",
      "Maximum validation accuracy : 65.93%\n",
      "\tTrial 8/ | Val Acc: 0.6592639684677124\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:30:17.501268Z",
     "start_time": "2025-08-22T18:30:17.496263Z"
    }
   },
   "cell_type": "code",
   "source": "S2_baseline_Ts_f, S3_baseline_Ts_f",
   "id": "1f4329b1dc1fbaa9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([np.float64(0.5897821187973022),\n",
       "  np.float64(0.78152996301651),\n",
       "  np.float64(0.5057008862495422)],\n",
       " [np.float64(0.6903553009033203),\n",
       "  np.float64(0.4534534513950348),\n",
       "  np.float64(0.6592639684677124)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T17:50:38.163888Z",
     "start_time": "2025-08-22T17:50:38.157917Z"
    }
   },
   "cell_type": "code",
   "source": "S2_baseline, S3_baseline",
   "id": "2eed25072405fa9c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([np.float64(0.38778746128082275),\n",
       "  np.float64(0.1743050366640091),\n",
       "  np.float64(0.7727593779563904),\n",
       "  np.float64(0.473270446062088),\n",
       "  np.float64(0.7787732481956482),\n",
       "  np.float64(0.17456021904945374),\n",
       "  np.float64(0.17270788550376892),\n",
       "  np.float64(0.18846412003040314),\n",
       "  np.float64(0.18199867010116577),\n",
       "  np.float64(0.4073053002357483)],\n",
       " [np.float64(0.6608116030693054),\n",
       "  np.float64(0.175761416554451),\n",
       "  np.float64(0.18091079592704773),\n",
       "  np.float64(0.1728624552488327),\n",
       "  np.float64(0.17657656967639923),\n",
       "  np.float64(0.1765071451663971),\n",
       "  np.float64(0.1748933643102646),\n",
       "  np.float64(0.7290608882904053),\n",
       "  np.float64(0.17831943929195404),\n",
       "  np.float64(0.17969734966754913)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:25:28.326982Z",
     "start_time": "2025-08-22T18:25:28.320968Z"
    }
   },
   "cell_type": "code",
   "source": "S2_baseline_Ts, S3_baseline_Ts",
   "id": "807379cc84abbd7b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([np.float64(0.42524418234825134),\n",
       "  np.float64(0.8022053837776184),\n",
       "  np.float64(0.18846412003040314),\n",
       "  np.float64(0.18814609944820404)],\n",
       " [np.float64(0.175761416554451),\n",
       "  np.float64(0.17657656967639923),\n",
       "  np.float64(0.1700507551431656),\n",
       "  np.float64(0.17969734966754913)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inter-session",
   "id": "70c6d5b0b960e210"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T17:50:38.139264Z",
     "start_time": "2025-08-22T17:42:16.189592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inter_session_K_S2 = inter_session_run(X_lst2, y_lst2)\n",
    "inter_session_K_S3 = inter_session_run(X_lst3, y_lst3)"
   ],
   "id": "6f72d5ec4ca1ba20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6303, 16, 14, 1) (6303,) (1000, 16, 14, 1) (1000,)\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 46.11%\n",
      "Maximum validation accuracy : 21.9%\n",
      "\tTrial 2/10/featsubject3_2019-12-11 Human Trial [19] | Val Acc: 0.21899999678134918\n",
      "(26399, 16, 14, 1) (26399,) (1000, 16, 14, 1) (1000,)\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 61.79%\n",
      "Maximum validation accuracy : 27.9%\n",
      "\tTrial 5/10/featsubject3_2019-12-11 Human Trial [19] | Val Acc: 0.27900001406669617\n",
      "(48077, 16, 14, 1) (48077,) (1000, 16, 14, 1) (1000,)\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 50.98%\n",
      "Maximum validation accuracy : 35.1%\n",
      "\tTrial 8/10/featsubject3_2019-12-11 Human Trial [19] | Val Acc: 0.35100001096725464\n",
      "(63084, 16, 14, 1) (63084,) (1000, 16, 14, 1) (1000,)\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 18.02%\n",
      "Maximum validation accuracy : 19.5%\n",
      "\tTrial 10/10/featsubject3_2019-12-11 Human Trial [19] | Val Acc: 0.19499999284744263\n",
      "(8251, 16, 14, 1) (8251,) (1000, 16, 14, 1) (1000,)\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 17.28%\n",
      "Maximum validation accuracy : 17.8%\n",
      "\tTrial 2/10/featsubject3_2019-12-11 Human Trial [19] | Val Acc: 0.17800000309944153\n",
      "(32212, 16, 14, 1) (32212,) (1000, 16, 14, 1) (1000,)\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 17.47%\n",
      "Maximum validation accuracy : 18.5%\n",
      "\tTrial 5/10/featsubject3_2019-12-11 Human Trial [19] | Val Acc: 0.1850000023841858\n",
      "(56777, 16, 14, 1) (56777,) (1000, 16, 14, 1) (1000,)\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 17.61%\n",
      "Maximum validation accuracy : 18.6%\n",
      "\tTrial 8/10/featsubject3_2019-12-11 Human Trial [19] | Val Acc: 0.1860000044107437\n",
      "(72447, 16, 14, 1) (72447,) (1000, 16, 14, 1) (1000,)\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 27.43%\n",
      "Maximum validation accuracy : 29.2%\n",
      "\tTrial 10/10/featsubject3_2019-12-11 Human Trial [19] | Val Acc: 0.2919999957084656\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T17:50:38.190091Z",
     "start_time": "2025-08-22T17:50:38.186193Z"
    }
   },
   "cell_type": "code",
   "source": "inter_session_K_S2, inter_session_K_S3",
   "id": "9ffb0602ce749da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([np.float64(0.21899999678134918),\n",
       "  np.float64(0.27900001406669617),\n",
       "  np.float64(0.35100001096725464),\n",
       "  np.float64(0.19499999284744263)],\n",
       " [np.float64(0.17800000309944153),\n",
       "  np.float64(0.1850000023841858),\n",
       "  np.float64(0.1860000044107437),\n",
       "  np.float64(0.2919999957084656)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "inter_session_K_S2 = inter_session_run(X_lst2, y_lst2)\n",
    "inter_session_K_S3 = inter_session_run(X_lst3, y_lst3)"
   ],
   "id": "1f87856f32293d4d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
