{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-11T23:16:10.264288Z",
     "start_time": "2025-07-11T23:16:07.976289Z"
    }
   },
   "source": [
    "import sys\n",
    "sys.path.append('../Share')\n",
    "import config\n",
    "import baseline\n",
    "import Target\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T23:21:51.525779Z",
     "start_time": "2025-07-11T23:21:40.103915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "baseline_K_val = [1, 4, 8, 12]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for K in baseline_K_val:\n",
    "        trainer = baseline.TremorModelTrainer(config, subject=\"Xianyu\")\n",
    "        trainer.run_all_sessions_training_K_data(K)\n",
    "        df = trainer.save_results(f'../Results/Baseline_results_train_with_{K}data_X.csv')\n",
    "\n",
    "# 저장해놨어서 데이터 업데이트 전에 한번 돌리면 굳이 안돌려도 됨'''"
   ],
   "id": "722bdc3c8cbe9ef3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1/16 - Session Exp_2025-06-24-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "(8521, 4, 14, 1) (8521,) (86, 4, 14, 1) (86,)\n",
      "Dataset 2/16 - Session Exp_2025-06-24-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is saved)\n",
      "Maximum training accuracy : 88.1%\n",
      "Maximum validation accuracy : 84.88%\n",
      "Accuracy of test dataset using model V0: 84.8837%\n",
      "Dataset 3/16 - Session Exp_2025-06-26-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 80.3945%\n",
      "Dataset 4/16 - Session Exp_2025-06-26-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 49.6957%\n",
      "Dataset 5/16 - Session Exp_2025-06-27-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 74.7408%\n",
      "Dataset 6/16 - Session Exp_2025-06-27-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 71.2760%\n",
      "Dataset 7/16 - Session Exp_2025-06-30-v1/FEFFF6FFF5FF/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 89.3234%\n",
      "Dataset 8/16 - Session Exp_2025-06-30-v2/FEFFF6FFF5FF/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 56.0377%\n",
      "Dataset 9/16 - Session Exp_2025-07-01-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 64.0093%\n",
      "Dataset 10/16 - Session Exp_2025-07-01-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 78.1008%\n",
      "Dataset 11/16 - Session Exp_2025-07-02-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 64.7274%\n",
      "Dataset 12/16 - Session Exp_2025-07-02-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 57.2685%\n",
      "Dataset 13/16 - Session Exp_2025-07-09-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 86.0573%\n",
      "Dataset 14/16 - Session Exp_2025-07-09-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 88.1861%\n",
      "Dataset 15/16 - Session Exp_2025-07-11-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 89.1027%\n",
      "Dataset 16/16 - Session Exp_2025-07-11-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Accuracy on unseen dataset: 87.8481%\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      5\u001B[39m         trainer = baseline.TremorModelTrainer(config, subject=\u001B[33m\"\u001B[39m\u001B[33mXianyu\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      6\u001B[39m         trainer.run_all_sessions_training_K_data(K)\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m         df = \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave_results\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m../Results/Baseline_results_train_with_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mK\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43mdata_X.csv\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[38;5;66;03m# 저장해놨어서 데이터 업데이트 전에 한번 돌리면 굳이 안돌려도 됨'''\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tremor_project_local\\NCI_mindforce\\github\\V4 feature encoding\\../Share\\baseline.py:136\u001B[39m, in \u001B[36mTremorModelTrainer.save_results\u001B[39m\u001B[34m(self, filepath)\u001B[39m\n\u001B[32m    135\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34msave_results\u001B[39m(\u001B[38;5;28mself\u001B[39m, filepath):\n\u001B[32m--> \u001B[39m\u001B[32m136\u001B[39m     df = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m    137\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mInfo\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minfo_labels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    138\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mInfo_Set\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset_info\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    139\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mAccuracy\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mresults\u001B[49m\n\u001B[32m    140\u001B[39m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    141\u001B[39m     df.to_csv(filepath, index=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m    142\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mResults saved to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilepath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tremor_project_local\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001B[39m, in \u001B[36mDataFrame.__init__\u001B[39m\u001B[34m(self, data, index, columns, dtype, copy)\u001B[39m\n\u001B[32m    772\u001B[39m     mgr = \u001B[38;5;28mself\u001B[39m._init_mgr(\n\u001B[32m    773\u001B[39m         data, axes={\u001B[33m\"\u001B[39m\u001B[33mindex\u001B[39m\u001B[33m\"\u001B[39m: index, \u001B[33m\"\u001B[39m\u001B[33mcolumns\u001B[39m\u001B[33m\"\u001B[39m: columns}, dtype=dtype, copy=copy\n\u001B[32m    774\u001B[39m     )\n\u001B[32m    776\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, \u001B[38;5;28mdict\u001B[39m):\n\u001B[32m    777\u001B[39m     \u001B[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m778\u001B[39m     mgr = \u001B[43mdict_to_mgr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmanager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    779\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ma.MaskedArray):\n\u001B[32m    780\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mma\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m mrecords\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tremor_project_local\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001B[39m, in \u001B[36mdict_to_mgr\u001B[39m\u001B[34m(data, index, columns, dtype, typ, copy)\u001B[39m\n\u001B[32m    499\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    500\u001B[39m         \u001B[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001B[39;00m\n\u001B[32m    501\u001B[39m         arrays = [x.copy() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(x, \u001B[33m\"\u001B[39m\u001B[33mdtype\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m arrays]\n\u001B[32m--> \u001B[39m\u001B[32m503\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marrays_to_mgr\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrays\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtyp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconsolidate\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tremor_project_local\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001B[39m, in \u001B[36marrays_to_mgr\u001B[39m\u001B[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001B[39m\n\u001B[32m    111\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m verify_integrity:\n\u001B[32m    112\u001B[39m     \u001B[38;5;66;03m# figure out the index, if necessary\u001B[39;00m\n\u001B[32m    113\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m114\u001B[39m         index = \u001B[43m_extract_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrays\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    115\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    116\u001B[39m         index = ensure_index(index)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tremor_project_local\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001B[39m, in \u001B[36m_extract_index\u001B[39m\u001B[34m(data)\u001B[39m\n\u001B[32m    675\u001B[39m lengths = \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mset\u001B[39m(raw_lengths))\n\u001B[32m    676\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(lengths) > \u001B[32m1\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m677\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mAll arrays must be of the same length\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    679\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m have_dicts:\n\u001B[32m    680\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    681\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mMixing dicts with non-Series may lead to ambiguous ordering.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    682\u001B[39m     )\n",
      "\u001B[31mValueError\u001B[39m: All arrays must be of the same length"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "b_path = 'C:/Users/hml76/PycharmProjects/Tremor_project_local/NCI_mindforce'\n",
    "baseline_K = ['1', '4', '8', '12']\n",
    "baselines = []\n",
    "\n",
    "for idx, K in enumerate(baseline_K):\n",
    "    baselines.append(b_path + f'/github/Results/Baseline_results_train_with_{K}data_H.csv')\n",
    "\n",
    "SUBJECT = \"Hunmin\""
   ],
   "id": "2e765482a9856fbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import Target\n",
    "\n",
    "prog_trainer = Target.ProgressiveTrainer(config, subject=SUBJECT)\n",
    "Init_acc_all, Prev_acc_all, Trained_acc_all = prog_trainer.run(plot_learning_curve=False)\n",
    "prog_trainer.plot_results(baselines, baseline_K)\n",
    "\n",
    "for idx, x in enumerate([Init_acc_all, Prev_acc_all, Trained_acc_all]):\n",
    "    if idx==0:\n",
    "        print(f\"Average of acc without training anything (should be random): {np.mean(x)*100:.2f}%\")\n",
    "    elif idx==1:\n",
    "        print(f\"Average of acc using previous test data after training: {np.mean(x)*100:.2f}%\")\n",
    "    elif idx==2:\n",
    "        print(f\"Average of acc using current test data after training: {np.mean(x)*100:.2f}%\")\n",
    "for idx, b in enumerate(baselines):\n",
    "    print(f\"Baseline K-{baseline_K[idx]}: {float(np.mean(pd.read_csv(baselines[idx])['Accuracy'][int(baseline_K[idx]):])):.2f}%\")"
   ],
   "id": "19a33d50b3192086",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "502cc2c5f5e11baa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c98c1b19228b774a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c099a5ce676f03b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2bcbd11baea9e18a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fb1223368b051901",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ee52469d1234b9cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "628e5de340ff4f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "650961d06f46be31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e7a973712efe1e03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b2082587589d7078",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
