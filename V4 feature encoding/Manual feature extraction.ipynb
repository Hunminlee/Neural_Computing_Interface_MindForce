{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T20:44:20.689698Z",
     "start_time": "2025-07-09T20:44:20.679170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../Share\")\n",
    "import config, utils, baseline\n",
    "\n",
    "\n",
    "from scipy.signal import lfilter, medfilt\n",
    "from scipy.signal import hilbert\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class EMGFeatureExtractor:\n",
    "    def __init__(self, feat_mean, feat_std, filter_b, filter_a, Norm_bool):\n",
    "        self.feat_mean = feat_mean\n",
    "        self.feat_std = feat_std\n",
    "        self.filter_b = filter_b\n",
    "        self.filter_a = filter_a\n",
    "        self.buffer = None  # to be set externally\n",
    "        self.normalization = Norm_bool\n",
    "\n",
    "\n",
    "    def extract_features(self, win_size=600, win_step=120, feat_exclude=60):\n",
    "        buf = lfilter(self.filter_b, self.filter_a, self.buffer, axis=1)\n",
    "        nch, len_x = buf.shape\n",
    "        n_steps = (len_x - win_size) // win_step + 1\n",
    "\n",
    "        features = np.zeros((nch, 14, n_steps))\n",
    "        for i in range(n_steps):\n",
    "            x = buf[:, i*win_step:i*win_step+win_size]\n",
    "            features[:, :, i] = self.extract_feature_win(x)\n",
    "\n",
    "        if self.normalization:\n",
    "            features = (features - self.feat_mean[:, :, np.newaxis]) / self.feat_std[:, :, np.newaxis]\n",
    "\n",
    "        if features.shape[2] > feat_exclude:\n",
    "            features = features[:, :, feat_exclude-1:]  # <-- FIXED HERE\n",
    "        return features\n",
    "\n",
    "\n",
    "    def extract_tail_features(self, feat_num, win_size=600, win_step=120):\n",
    "        n_samples = win_size + (feat_num - 1) * win_step\n",
    "        if self.buffer.shape[1] < n_samples:\n",
    "            return None\n",
    "\n",
    "        buf = self.buffer[:, -n_samples:]\n",
    "        buf = lfilter(self.filter_b, self.filter_a, buf, axis=1)\n",
    "\n",
    "        nch, len_x = buf.shape\n",
    "        n_steps = (len_x - win_size) // win_step + 1\n",
    "        features = np.zeros((nch, 14, n_steps))\n",
    "\n",
    "        for i in range(n_steps):\n",
    "            x = buf[:, i*win_step:i*win_step+win_size]\n",
    "            features[:, :, i] = self.extract_feature_win(x)\n",
    "\n",
    "        features = (features - self.feat_mean[:, :, np.newaxis]) / self.feat_std[:, :, np.newaxis]\n",
    "        return features\n",
    "\n",
    "\n",
    "    def filter_features(self, features):\n",
    "        reshaped = features.reshape(features.shape[0]*features.shape[1], -1).T\n",
    "        pca = PCA(n_components=1)\n",
    "        pcomp = pca.fit_transform(reshaped).squeeze()\n",
    "        pcomp = (pcomp - np.mean(pcomp)) / np.std(pcomp)\n",
    "        med = medfilt(pcomp, kernel_size=5)\n",
    "\n",
    "        if np.mean(med[:40]) > 0:\n",
    "            med = -med\n",
    "\n",
    "        # RMS envelope approximation\n",
    "        window_size = 3\n",
    "        rms_env = np.sqrt(np.convolve(med**2, np.ones(window_size)/window_size, mode='same'))\n",
    "        med = (med - rms_env) - 0.5\n",
    "        return med\n",
    "\n",
    "\n",
    "    def extract_feature_win(self, x):\n",
    "        len_x = x.shape[1]\n",
    "        sum_x = np.sum(x, axis=1)\n",
    "        mean_x = sum_x / len_x\n",
    "        ssq_x = np.sum(x**2, axis=1)\n",
    "        std_x = np.sqrt((ssq_x - 2*sum_x*mean_x + len_x*mean_x**2)/(len_x-1))\n",
    "        diff_x = np.diff(x, axis=1)\n",
    "\n",
    "        zc = np.mean(np.sign(x[:,1:]) != np.sign(x[:,:-1]), axis=1)\n",
    "        ssc = np.mean(np.sign(diff_x[:,1:]) != np.sign(diff_x[:,:-1]), axis=1)\n",
    "        wl = np.mean(np.abs(diff_x), axis=1)\n",
    "        wamp = np.mean(np.abs(np.diff(x, axis=1)) > std_x[:, np.newaxis], axis=1)\n",
    "        mab = np.mean(np.abs(x), axis=1)\n",
    "        msq = ssq_x / len_x\n",
    "        rms = np.sqrt(msq)\n",
    "        v3 = np.cbrt(np.mean(x**3, axis=1))\n",
    "        lgdec = np.exp(np.mean(np.log(np.abs(x) + 1), axis=1))\n",
    "        dabs = np.sqrt(np.mean(diff_x**2, axis=1))\n",
    "        mfl = np.log(np.sqrt(np.mean(diff_x**2, axis=1)) + 1)\n",
    "        mpr = np.mean(x > std_x[:, np.newaxis], axis=1)\n",
    "        mid = x.shape[1] // 2\n",
    "        mavs = np.mean(np.abs(x[:, mid:]), axis=1) - np.mean(np.abs(x[:, :mid]), axis=1)\n",
    "\n",
    "        weight = np.ones_like(x)\n",
    "        weight[:, :int(0.25*len_x)] = 0.5\n",
    "        weight[:, int(0.75*len_x):] = 0.5\n",
    "        wmab = np.mean(weight * np.abs(x), axis=1)\n",
    "\n",
    "        return np.stack([zc, ssc, wl, wamp, mab, msq, rms, v3, lgdec, dabs, mfl, mpr, mavs, wmab], axis=1)\n",
    "\n",
    "from scipy.signal import cheby2\n",
    "\n",
    "def create_cheby2_bandpass(fs, low_cutoff, high_cutoff, order=4, rs=30):\n",
    "    nyq = fs / 2\n",
    "    low = max(1, low_cutoff) / nyq\n",
    "    high = min(0.99 * fs / 2, high_cutoff) / nyq\n",
    "    b, a = cheby2(order, rs, [low, high], btype='bandpass')\n",
    "    return b, a\n",
    "\n",
    "#filter_b, filter_a = create_cheby2_bandpass(fs, lower_cutoff, upper_cutoff)"
   ],
   "id": "df8dd3a912157c6e",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Sync up to the Data_ADC and Data_Cls\n",
    "2. Extract features\n",
    "3. Normalization problem\n",
    "    - Without Norm.\n",
    "4."
   ],
   "id": "b4e1fa8f28509758"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T20:00:56.363745Z",
     "start_time": "2025-07-09T20:00:56.359089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fs = round(10e6 / 2048)  # 4883 Hz\n",
    "lower_cutoff = 100\n",
    "upper_cutoff = 600\n",
    "filter_b, filter_a = cheby2(4, 30, [lower_cutoff / (fs/2), upper_cutoff / (fs/2)], btype='bandpass')\n",
    "\n",
    "feat_mean_1ch = np.array([0.1, 0.1, 2.5, 0.0, 11.0, 229.0, 13.8, -11.0, 9.0, 3.0, 1.5, 0.0, 0.0, 2.8])\n",
    "feat_std_1ch = np.array([0.02, 0.05, 0.65, 0.02, 4.43, 303.9, 6.85, 12.18, 2.87, 0.87, 0.21, 0.04, 6.68, 1.12])\n",
    "feat_mean = np.tile(feat_mean_1ch, (4, 1))\n",
    "feat_std = np.tile(feat_std_1ch, (4, 1))\n",
    "\n",
    "extractor = EMGFeatureExtractor(feat_mean, feat_std, filter_b, filter_a, Norm_bool=False)\n",
    "trainer = baseline.TremorModelTrainer(config, subject=\"Hunmin\")"
   ],
   "id": "f8a48a6abfc823e2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T20:00:56.375018Z",
     "start_time": "2025-07-09T20:00:56.371753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#path = 'C:/Users/hml76/OneDrive/문서/MATLAB/Data_Hunmin/Exp_2025-07-02-v4/E9AD0E7DCC2B/raw/1/'\n",
    "#mat = scipy.io.loadmat(path+'Data_20250702_141831.mat')\n",
    "#raw_emg_data = mat['Data_ADC']\n",
    "#extractor.buffer = raw_emg_data  # shape: (4, 215040)\n",
    "#features = extractor.extract_features()\n",
    "#print(features.shape)  # → (4, 14, 1787)"
   ],
   "id": "ed7e8810b465dae2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T20:12:56.399490Z",
     "start_time": "2025-07-09T20:11:23.545050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_files = config.dataset_sub_H\n",
    "default_path = config.default_path_sub_H\n",
    "\n",
    "baseline_K = ['1', '6', '10', '14', '18', '22', '26', '30', '34', '38']\n",
    "for K in baseline_K:\n",
    "    X_train_all, y_train_all, X_test_all, y_test_all = [], [], [], []\n",
    "    ACC_all = []\n",
    "\n",
    "    for idx, session_info in enumerate(data_files):\n",
    "    #for idx, session_info in enumerate(['Exp_2025-06-27-v1/E9AD0E7DCC2B/']):\n",
    "        #print(f\"Dataset {idx + 1}/{len(data_files)} - Session {session_info}\\n{'='*40}\")\n",
    "        path = os.path.join(default_path, f'{session_info}raw/')\n",
    "        features, class_labels = [], []\n",
    "        for c_idx, c in enumerate(config.classes_5):\n",
    "            raw_data = os.listdir(path+c)\n",
    "            mat = scipy.io.loadmat(path+c+raw_data[0])\n",
    "            extractor.buffer = mat['Data_ADC']\n",
    "            class_labels.append(mat['Data_Cls'].reshape(-1))\n",
    "            features_per_cls = extractor.extract_features()\n",
    "            features_per_cls = np.transpose(features_per_cls, (2, 0, 1))  # shape: (1729, 4, 14)\n",
    "            features.append(features_per_cls)\n",
    "            #print(features_per_cls.shape, mat['Data_Cls'].reshape(-1).shape)\n",
    "\n",
    "        print(session_info)\n",
    "        X = np.concatenate(features, axis=0)\n",
    "        y = np.concatenate(class_labels, axis=0)\n",
    "\n",
    "        if X.shape[0] != y.shape[-1]:\n",
    "            print(f\"Incorrect shape between features and Class: {X.shape} and {y.shape}, {session_info}\")\n",
    "            break\n",
    "\n",
    "        if idx < K:\n",
    "            X_train, y_train, X_test, y_test = utils.split_data(X, y, ratio=0.9)\n",
    "            X_train_all.append(X_train)\n",
    "            y_train_all.append(y_train)\n",
    "            X_test_all.append(X_test)\n",
    "            y_test_all.append(y_test)\n",
    "\n",
    "            # Concatenate all so far\n",
    "            X_train_stacked = np.concatenate(X_train_all, axis=0)\n",
    "            y_train_stacked = np.concatenate(y_train_all, axis=0)\n",
    "            X_test_stacked = np.concatenate(X_test_all, axis=0)\n",
    "            y_test_stacked = np.concatenate(y_test_all, axis=0)\n",
    "            acc=0\n",
    "        elif idx == K:\n",
    "            print(X_train_stacked.shape, y_train_stacked.shape)\n",
    "            acc, pre_trained_CNN = trainer.train_multiple_dataset(X_train, y_train, X_test, y_test)\n",
    "        else:\n",
    "            #Test with current data\n",
    "            X = np.expand_dims(X, axis=-1)\n",
    "            acc = pre_trained_CNN.evaluate(X, y, verbose=0)[1]\n",
    "            print(f\"\\t Accuracy on unseen dataset {idx+1}: {acc * 100:.4f}%\")\n",
    "        ACC_all.append(acc)\n",
    "    pd.DataFrame(ACC_all)\n",
    "\n"
   ],
   "id": "99088d65261b5b7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "Exp_2025-05-27/E8331D05289A/\n",
      "(1729, 4, 14) (1729,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1720, 4, 14) (1720,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "Exp_2025-06-18/E9AD0E7DCC2B/\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1677, 4, 14) (1677,)\n",
      "Exp_2025-06-20-v1/E9AD0E7DCC2B/\n",
      "(1720, 4, 14) (1720,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1716, 4, 14) (1716,)\n",
      "Exp_2025-06-20-v2/E9AD0E7DCC2B/\n",
      "(1592, 4, 14) (1592,)\n",
      "(1191, 4, 14) (1191,)\n",
      "(1494, 4, 14) (1494,)\n",
      "(1686, 4, 14) (1686,)\n",
      "(1724, 4, 14) (1724,)\n",
      "Exp_2025-06-20-v3/E9AD0E7DCC2B/\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1720, 4, 14) (1720,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "Exp_2025-06-20-v4/E9AD0E7DCC2B/\n",
      "(1724, 4, 14) (1724,)\n",
      "(1711, 4, 14) (1711,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1707, 4, 14) (1707,)\n",
      "Exp_2025-06-20-v5/E9AD0E7DCC2B/\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "Exp_2025-06-20-v6/E9AD0E7DCC2B/\n",
      "(1729, 4, 14) (1729,)\n",
      "(1720, 4, 14) (1720,)\n",
      "(1711, 4, 14) (1711,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1720, 4, 14) (1720,)\n",
      "Exp_2025-06-20-v7/E9AD0E7DCC2B/\n",
      "(1729, 4, 14) (1729,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1716, 4, 14) (1716,)\n",
      "Exp_2025-06-20-v8/E9AD0E7DCC2B/\n",
      "(1720, 4, 14) (1720,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1673, 4, 14) (1673,)\n",
      "(1720, 4, 14) (1720,)\n",
      "Exp_2025-06-23-v1/E9AD0E7DCC2B/\n",
      "(1703, 4, 14) (1703,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1720, 4, 14) (1720,)\n",
      "(1690, 4, 14) (1690,)\n",
      "(1699, 4, 14) (1699,)\n",
      "Exp_2025-06-23-v2/E9AD0E7DCC2B/\n",
      "(1643, 4, 14) (1643,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1720, 4, 14) (1720,)\n",
      "(1729, 4, 14) (1729,)\n",
      "Exp_2025-06-23-v3/E9AD0E7DCC2B/\n",
      "(1703, 4, 14) (1703,)\n",
      "(1639, 4, 14) (1639,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1690, 4, 14) (1690,)\n",
      "(1711, 4, 14) (1711,)\n",
      "Exp_2025-06-23-v4/E9AD0E7DCC2B/\n",
      "(1724, 4, 14) (1724,)\n",
      "(1711, 4, 14) (1711,)\n",
      "(1694, 4, 14) (1694,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "Exp_2025-06-24-v1/E9AD0E7DCC2B/\n",
      "(1660, 4, 14) (1660,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "Exp_2025-06-24-v2/E9AD0E7DCC2B/\n",
      "(1716, 4, 14) (1716,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1720, 4, 14) (1720,)\n",
      "(1720, 4, 14) (1720,)\n",
      "(1724, 4, 14) (1724,)\n",
      "Exp_2025-06-24-v3/E9AD0E7DCC2B/\n",
      "(1413, 4, 14) (1413,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1716, 4, 14) (1716,)\n",
      "(1724, 4, 14) (1724,)\n",
      "Exp_2025-06-24-v4/E9AD0E7DCC2B/\n",
      "(1724, 4, 14) (1724,)\n",
      "(1677, 4, 14) (1677,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "Exp_2025-06-26-v1/E9AD0E7DCC2B/\n",
      "(138049, 4, 14, 1) (138049,)\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is saved)\n",
      "Maximum training accuracy : 93.83%\n",
      "Maximum validation accuracy : 96.27%\n",
      "Accuracy of test dataset using model V0: 96.0289%\n",
      "(1690, 4, 14) (1690,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1699, 4, 14) (1699,)\n",
      "(1720, 4, 14) (1720,)\n",
      "Exp_2025-06-26-v2/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 20: 78.1604%\n",
      "(1729, 4, 14) (1729,)\n",
      "(1720, 4, 14) (1720,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1699, 4, 14) (1699,)\n",
      "(1729, 4, 14) (1729,)\n",
      "Exp_2025-06-26-v3/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 21: 88.0712%\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1720, 4, 14) (1720,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "Exp_2025-06-26-v4/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 22: 87.7624%\n",
      "(1720, 4, 14) (1720,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1528, 4, 14) (1528,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1707, 4, 14) (1707,)\n",
      "Exp_2025-06-27-v1/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 23: 80.3404%\n",
      "(1729, 4, 14) (1729,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "Exp_2025-06-27-v2/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 24: 84.0904%\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1647, 4, 14) (1647,)\n",
      "Exp_2025-06-27-v3/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 25: 78.7217%\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1720, 4, 14) (1720,)\n",
      "(1694, 4, 14) (1694,)\n",
      "Exp_2025-06-27-v4/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 26: 75.2676%\n",
      "(1729, 4, 14) (1729,)\n",
      "(1703, 4, 14) (1703,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1626, 4, 14) (1626,)\n",
      "(1690, 4, 14) (1690,)\n",
      "Exp_2025-06-30-v1/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 27: 74.1856%\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1694, 4, 14) (1694,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "Exp_2025-06-30-v2/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 28: 85.4567%\n",
      "(1545, 4, 14) (1545,)\n",
      "(1711, 4, 14) (1711,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1711, 4, 14) (1711,)\n",
      "(1716, 4, 14) (1716,)\n",
      "Exp_2025-06-30-v3/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 29: 88.4332%\n",
      "(1711, 4, 14) (1711,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1656, 4, 14) (1656,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1720, 4, 14) (1720,)\n",
      "Exp_2025-06-30-v4/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 30: 79.1916%\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1720, 4, 14) (1720,)\n",
      "(1716, 4, 14) (1716,)\n",
      "(1729, 4, 14) (1729,)\n",
      "Exp_2025-07-01-v1/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 31: 76.7328%\n",
      "(1720, 4, 14) (1720,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "Exp_2025-07-01-v2/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 32: 82.4846%\n",
      "(1724, 4, 14) (1724,)\n",
      "(1716, 4, 14) (1716,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1724, 4, 14) (1724,)\n",
      "Exp_2025-07-01-v3/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 33: 83.4377%\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1711, 4, 14) (1711,)\n",
      "(1720, 4, 14) (1720,)\n",
      "Exp_2025-07-01-v4/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 34: 82.2013%\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1716, 4, 14) (1716,)\n",
      "(1716, 4, 14) (1716,)\n",
      "(1724, 4, 14) (1724,)\n",
      "Exp_2025-07-02-v1/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 35: 82.6360%\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "Exp_2025-07-02-v2/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 36: 83.9560%\n",
      "(1724, 4, 14) (1724,)\n",
      "(1720, 4, 14) (1720,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1699, 4, 14) (1699,)\n",
      "Exp_2025-07-02-v3/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 37: 88.1224%\n",
      "(1729, 4, 14) (1729,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "Exp_2025-07-02-v4/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 38: 73.8657%\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1707, 4, 14) (1707,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1720, 4, 14) (1720,)\n",
      "Exp_2025-07-03-v1/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 39: 67.0810%\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "Exp_2025-07-03-v2/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 40: 88.8130%\n",
      "(1729, 4, 14) (1729,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "Exp_2025-07-03-v3/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 41: 89.9479%\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "Exp_2025-07-03-v4/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 42: 73.1134%\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1711, 4, 14) (1711,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1720, 4, 14) (1720,)\n",
      "Exp_2025-07-07-v1/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 43: 87.2128%\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "Exp_2025-07-07-v2/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 44: 89.1594%\n",
      "(1729, 4, 14) (1729,)\n",
      "(1711, 4, 14) (1711,)\n",
      "(1643, 4, 14) (1643,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1665, 4, 14) (1665,)\n",
      "Exp_2025-07-07-v3/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 45: 90.2974%\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "Exp_2025-07-07-v4/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 46: 89.6640%\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1724, 4, 14) (1724,)\n",
      "Exp_2025-07-09-v1/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 47: 88.4887%\n",
      "(1729, 4, 14) (1729,)\n",
      "(1720, 4, 14) (1720,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1729, 4, 14) (1729,)\n",
      "Exp_2025-07-09-v2/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 48: 89.7694%\n",
      "(1716, 4, 14) (1716,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "(1724, 4, 14) (1724,)\n",
      "Exp_2025-07-09-v3/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 49: 92.1389%\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1720, 4, 14) (1720,)\n",
      "(1729, 4, 14) (1729,)\n",
      "(1729, 4, 14) (1729,)\n",
      "Exp_2025-07-09-v4/E9AD0E7DCC2B/\n",
      "\t Accuracy on unseen dataset 50: 91.6628%\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "643d915c67c1e3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T20:46:06.487503Z",
     "start_time": "2025-07-09T20:46:06.472504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ACC_all = [1,2,3]\n",
    "pd.DataFrame(ACC_all).to_csv(f'../Results/Baseline_results_train_with_{K}data_noNorm_H.csv')\n",
    "\n"
   ],
   "id": "728da4037468e8b0",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fd2e11e70a04629e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3d789a9217e94dc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fd498775888dc866",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "699a1e49083892b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "42f9c9ec5bd8e9ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f0e04b58a340454",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "df325c57cdcb08c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fdf0dfe29349e0f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "99738376c25eff0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9c15e3b0ad9ab099",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_dataset(path, classes, show_labels):\n",
    "    for c_idx, c in enumerate(classes):\n",
    "        raw_data = os.listdir(path+c)\n",
    "        if len(raw_data) == 1:\n",
    "            mat = scipy.io.loadmat(path+c+raw_data[0])\n",
    "        else:\n",
    "            print(f\"There is more than one dataset - check - {path} - {classes}\")\n",
    "\n",
    "        if c_idx == 0:\n",
    "            #print(f\"Import matlab raw dataset - Matlab file Keys: {mat.keys()}\")\n",
    "            pass\n",
    "\n",
    "\n",
    "        if c_idx == 0:\n",
    "            feature_set = np.transpose(mat['Data_ADC'], (2, 0, 1))  # shape: (1729, 4, 14)\n",
    "            labels = mat['Data_Cls'].flatten()  #0 or class (either one)\n",
    "\n",
    "        elif c_idx > 0:\n",
    "            feature_set_added = np.transpose(mat['Data_ADC'], (2, 0, 1))\n",
    "            labels_addend = mat['Data_Cls'].flatten()  #0 or class (either one)\n",
    "\n",
    "            feature_set = np.concatenate([feature_set, feature_set_added], axis=0)\n",
    "            labels = np.concatenate([labels, labels_addend], axis=0)\n",
    "        else:\n",
    "            print(\"Error in c_idx\")\n",
    "            break\n",
    "\n",
    "    return feature_set, labels"
   ],
   "id": "1984901fbefedfae",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def get_dataset(path, classes, show_labels):\n",
    "    for c_idx, c in enumerate(classes):\n",
    "        raw_data = os.listdir(path+c)\n",
    "        if len(raw_data) == 1:\n",
    "            mat = scipy.io.loadmat(path+c+raw_data[0])\n",
    "        else:\n",
    "            print(f\"There is more than one dataset - check - {path} - {classes}\")\n",
    "\n",
    "        if c_idx == 0:\n",
    "            #print(f\"Import matlab raw dataset - Matlab file Keys: {mat.keys()}\")\n",
    "            pass\n",
    "\n",
    "        if mat['Data_Cls'].shape[-1] != mat['Data_ADC'].shape[-1]:\n",
    "            print(f\"Label and dataset do not match! : {len(mat['Data_Cls'])}, {len(mat['Data_Fea'])}\")\n",
    "            break\n",
    "\n",
    "        if c_idx == 0:\n",
    "            feature_set = np.transpose(mat['Data_ADC'], (2, 0, 1))  # shape: (1729, 4, 14)\n",
    "            labels = mat['Data_Cls'].flatten()  #0 or class (either one)\n",
    "\n",
    "        elif c_idx > 0:\n",
    "            feature_set_added = np.transpose(mat['Data_ADC'], (2, 0, 1))\n",
    "            labels_addend = mat['Data_Cls'].flatten()  #0 or class (either one)\n",
    "\n",
    "            feature_set = np.concatenate([feature_set, feature_set_added], axis=0)\n",
    "            labels = np.concatenate([labels, labels_addend], axis=0)\n",
    "        else:\n",
    "            print(\"Error in c_idx\")\n",
    "            break\n",
    "\n",
    "    if show_labels:\n",
    "        plt.figure(figsize=(8,3))\n",
    "        plt.plot(labels)\n",
    "        plt.ylabel('Class label', fontsize=13)\n",
    "        plt.xlabel('Samples', fontsize=13)\n",
    "        plt.grid(True, which='both', linestyle='--')\n",
    "        plt.show()\n",
    "\n",
    "    return feature_set, labels"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "232633d33767c5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5b4669bb8fc572e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6a51b20a5be8e8df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "default_path = config.default_path_sub_H\n",
    "dataset_info = config.dataset_sub_H\n",
    "\n",
    "path = os.path.join(default_path, f'{session_info}/raw/')\n",
    "\n",
    "feature_set, labels = get_dataset(path, classes, show_labels=False)\n",
    "X_train, y_train, X_test, y_test = utils.split_data(feature_set, labels, ratio=train_ratio)"
   ],
   "id": "af84b2cd18bca831",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6881c403c295efb4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
