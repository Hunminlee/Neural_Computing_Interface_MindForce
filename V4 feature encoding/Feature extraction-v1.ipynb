{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../Share\")\n",
    "import config, utils, baseline, Processing_same_with_MATLAB\n",
    "\n",
    "\n",
    "fs = round(10e6 / 2048)  # 4883 Hz\n",
    "lower_cutoff = 100\n",
    "upper_cutoff = 600\n",
    "filter_b, filter_a = Processing_same_with_MATLAB.cheby2(4, 30, [lower_cutoff / (fs/2), upper_cutoff / (fs/2)], btype='bandpass')\n",
    "\n",
    "feat_mean_1ch = np.array([0.1, 0.1, 2.5, 0.0, 11.0, 229.0, 13.8, -11.0, 9.0, 3.0, 1.5, 0.0, 0.0, 2.8])\n",
    "feat_std_1ch = np.array([0.02, 0.05, 0.65, 0.02, 4.43, 303.9, 6.85, 12.18, 2.87, 0.87, 0.21, 0.04, 6.68, 1.12])\n",
    "feat_mean = np.tile(feat_mean_1ch, (4, 1))\n",
    "feat_std = np.tile(feat_std_1ch, (4, 1))\n",
    "\n",
    "extractor = Processing_same_with_MATLAB.EMGFeatureExtractor(feat_mean, feat_std, filter_b, filter_a, Norm_bool=False)\n",
    "trainer = baseline.TremorModelTrainer(config, subject=\"Hunmin\")"
   ],
   "id": "df8dd3a912157c6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Found that there are normalization applied, so I've tested it without using an normalization",
   "id": "9ad6a1a4d54cd975"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_files = config.dataset_sub_H\n",
    "default_path = config.default_path_sub_H\n",
    "\n",
    "baseline_K = [1, 6, 10, 14, 18, 22, 26, 30, 34, 38]\n",
    "for K in baseline_K:\n",
    "    X_train_all, y_train_all, X_test_all, y_test_all = [], [], [], []\n",
    "    ACC_all = []\n",
    "\n",
    "    for idx, session_info in enumerate(data_files):\n",
    "    #for idx, session_info in enumerate(['Exp_2025-06-27-v1/E9AD0E7DCC2B/']):\n",
    "        #print(f\"Dataset {idx + 1}/{len(data_files)} - Session {session_info}\\n{'='*40}\")\n",
    "        path = os.path.join(default_path, f'{session_info}raw/')\n",
    "        features, class_labels = [], []\n",
    "        for c_idx, c in enumerate(config.classes_5):\n",
    "            raw_data = os.listdir(path+c)\n",
    "            mat = scipy.io.loadmat(path+c+raw_data[0])\n",
    "            extractor.buffer = mat['Data_ADC']\n",
    "            class_labels.append(mat['Data_Cls'].reshape(-1))\n",
    "            features_per_cls = extractor.extract_features()\n",
    "            features_per_cls = np.transpose(features_per_cls, (2, 0, 1))  # shape: (1729, 4, 14)\n",
    "            features.append(features_per_cls)\n",
    "            #print(features_per_cls.shape, mat['Data_Cls'].reshape(-1).shape)\n",
    "\n",
    "        #print(session_info)\n",
    "        X = np.concatenate(features, axis=0)\n",
    "        y = np.concatenate(class_labels, axis=0)\n",
    "\n",
    "        if X.shape[0] != y.shape[-1]:\n",
    "            print(f\"Incorrect shape between features and Class: {X.shape} and {y.shape}, {session_info}\")\n",
    "            break\n",
    "\n",
    "        if idx < K:\n",
    "            X_train, y_train, X_test, y_test = utils.split_data(X, y, ratio=0.9)\n",
    "            X_train_all.append(X_train)\n",
    "            y_train_all.append(y_train)\n",
    "            X_test_all.append(X_test)\n",
    "            y_test_all.append(y_test)\n",
    "\n",
    "            # Concatenate all so far\n",
    "            X_train_stacked = np.concatenate(X_train_all, axis=0)\n",
    "            y_train_stacked = np.concatenate(y_train_all, axis=0)\n",
    "            X_test_stacked = np.concatenate(X_test_all, axis=0)\n",
    "            y_test_stacked = np.concatenate(y_test_all, axis=0)\n",
    "            acc=0\n",
    "        elif idx == K:\n",
    "            print(f\"\\t Training {K}: \", X_train_stacked.shape, y_train_stacked.shape)\n",
    "            acc, pre_trained_CNN = trainer.train_multiple_dataset(X_train, y_train, X_test, y_test)\n",
    "        else:\n",
    "            #Test with current data\n",
    "            X = np.expand_dims(X, axis=-1)\n",
    "            acc = pre_trained_CNN.evaluate(X, y, verbose=0)[1]*100\n",
    "            print(f\"\\t Accuracy on unseen dataset {idx+1}: {acc:.4f}%\")\n",
    "        ACC_all.append(acc)\n",
    "    pd.DataFrame(ACC_all).to_csv(f'../Results/WithoutNorm/Baseline_results_train_with_{K}data_noNorm_H.csv', index=False)"
   ],
   "id": "99088d65261b5b7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "b_path = 'C:/Users/hml76/PycharmProjects/Tremor_project_local/NCI_mindforce'\n",
    "baseline_K_char = ['1', '6', '10', '14', '18', '22', '26', '30', '34', '38']\n",
    "baselines, baselines_N = [], []\n",
    "\n",
    "for idx, K in enumerate(baseline_K_char):\n",
    "    baselines.append(b_path + f'/github/Results/Baseline_results_train_with_{K}data_H.csv')\n",
    "    baselines_N.append(b_path + f'/github/Results/WithoutNorm/Baseline_results_train_with_{K}data_noNorm_H.csv')\n",
    "\n",
    "for idx, b in enumerate(baseline_K_char):\n",
    "    ACC_with_norm = float(np.mean(pd.read_csv(baselines[idx])['Accuracy'][int(baseline_K[idx]):]))\n",
    "    ACC_without_norm = float(np.mean(pd.read_csv(baselines_N[idx])[int(baseline_K[idx]):]))\n",
    "    print(f\"Baseline K-{baseline_K_char[idx]}: Norm : {ACC_with_norm:.2f}% / Without Norm: {ACC_without_norm:.2f}%\")\n"
   ],
   "id": "643d915c67c1e3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6881c403c295efb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Normalization is better\n",
    "- How to set the normalization value remains a question"
   ],
   "id": "bbb9521fc414f1eb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
