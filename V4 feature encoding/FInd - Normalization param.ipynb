{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Search good hyper-parameters in Normalization\n",
    "- It seems finding a good value helps a lot in performance"
   ],
   "id": "e0b2aeb92e6f70b1"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-12T22:20:58.745622Z",
     "start_time": "2025-07-12T22:16:52.177936Z"
    }
   },
   "source": [
    "import sys\n",
    "sys.path.append(\"../Share\")\n",
    "import config, utils, baseline, Trainer, Processing_same_with_MATLAB\n",
    "import os\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "baseline_K_val = [18] #Train ~18 session data, test with 19~\n",
    "K = baseline_K_val[0]\n",
    "\n",
    "feature_names = ['Zero Crossing (ZC)', 'Slope Sign Changes (SSC)', 'Waveform Length (WL)', 'WAMP', 'Mean Absolute Value (MAV)', 'Mean Square (MS)', 'Root Mean Square (RMS)',\n",
    "                 'v-order 3 (V3)', 'log detector (LD)', 'difference absolute standard deviation value (DASDV)', 'maximum fractal length (MFL)', 'myopulse percentage rate (MPR)',\n",
    "                 'mean absolute value slope (MAVS)', 'weighted mean absolute (WMS)',\n",
    "                 'Cepstrum Coefficient 1', 'Cepstrum Coefficient 2', 'Cepstrum Coefficient 3', 'Cepstrum Coefficient Average', 'DWTC1', 'DWTC2',\n",
    "                 'DWTPC1', 'DWTPC2', 'DWTPC3']\n",
    "\n",
    "\n",
    "feature_idx = range(0,len(feature_names))\n",
    "\n",
    "fs = round(10e6 / 2048)  # 4883 Hz\n",
    "lower_cutoff = 100\n",
    "upper_cutoff = 600\n",
    "filter_b, filter_a = Processing_same_with_MATLAB.cheby2(4, 30, [lower_cutoff / (fs/2), upper_cutoff / (fs/2)], btype='bandpass')\n",
    "\n",
    "feat_mean_1ch = np.array([0.1, 0.1, 2.5, 0.0, 11.0, 229.0, 13.8, -11.0, 9.0, 3.0, 1.5, 0.0, 0.0, 2.8])\n",
    "feat_std_1ch = np.array([0.02, 0.05, 0.65, 0.02, 4.43, 303.9, 6.85, 12.18, 2.87, 0.87, 0.21, 0.04, 6.68, 1.12])\n",
    "feat_mean = np.tile(feat_mean_1ch, (4, 1))\n",
    "feat_std = np.tile(feat_std_1ch, (4, 1))\n",
    "\n",
    "data_files = config.dataset_sub_H\n",
    "default_path = config.default_path_sub_H\n",
    "Normalization_TF = False ############################ important!!!!\n",
    "\n",
    "\n",
    "extractor = Processing_same_with_MATLAB.EMGFeatureExtractor(feat_mean, feat_std, filter_b, filter_a, Norm_bool=Normalization_TF)\n",
    "X_train_all, y_train_all, X_test_all, y_test_all = [], [], [], []\n",
    "\n",
    "for idx, session_info in enumerate(data_files):\n",
    "    print(f\"Dataset {idx + 1}/{len(data_files)} - Session {session_info}\\n{'='*40}\")\n",
    "    path = os.path.join(default_path, f'{session_info}raw/')\n",
    "    features, class_labels = [], []\n",
    "    for c_idx, c in enumerate(config.classes_5):\n",
    "        raw_data = os.listdir(path+c)\n",
    "        mat = scipy.io.loadmat(path+c+raw_data[0])\n",
    "        extractor.buffer = mat['Data_ADC']\n",
    "        class_labels.append(mat['Data_Cls'].reshape(-1))\n",
    "        features_per_cls = extractor.extract_features(num_feature_set=23)\n",
    "        features_per_cls = np.transpose(features_per_cls, (2, 0, 1))  # shape: (1729, 4, 14)\n",
    "        features.append(features_per_cls)\n",
    "        #print(features_per_cls.shape, mat['Data_Cls'].reshape(-1).shape)\n",
    "\n",
    "    X = np.concatenate(features, axis=0)\n",
    "    y = np.concatenate(class_labels, axis=0)\n",
    "    if X.shape[0] != y.shape[-1]:\n",
    "        print(f\"Incorrect shape between features and Class: {X.shape} and {y.shape}, {session_info}\")\n",
    "        break\n",
    "\n",
    "    if idx < K:\n",
    "        X_train, y_train, _, _,  = utils.split_data(X, y, ratio=1)\n",
    "        X_train_all.append(X_train)\n",
    "        y_train_all.append(y_train)\n",
    "\n",
    "    else:\n",
    "        X_test, y_test, _, _ = utils.split_data(X, y, ratio=1)\n",
    "        X_test_all.append(X_test)\n",
    "        y_test_all.append(y_test)\n",
    "\n",
    "X_train_stacked = np.concatenate(X_train_all, axis=0)\n",
    "y_train_stacked = np.concatenate(y_train_all, axis=0)\n",
    "X_test_stacked = np.concatenate(X_test_all, axis=0)\n",
    "y_test_stacked = np.concatenate(y_test_all, axis=0)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1/58 - Session Exp_2025-05-27/E8331D05289A/\n",
      "========================================\n",
      "Dataset 2/58 - Session Exp_2025-06-18/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 3/58 - Session Exp_2025-06-20-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 4/58 - Session Exp_2025-06-20-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 5/58 - Session Exp_2025-06-20-v3/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 6/58 - Session Exp_2025-06-20-v4/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 7/58 - Session Exp_2025-06-20-v5/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 8/58 - Session Exp_2025-06-20-v6/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 9/58 - Session Exp_2025-06-20-v7/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 10/58 - Session Exp_2025-06-20-v8/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 11/58 - Session Exp_2025-06-23-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 12/58 - Session Exp_2025-06-23-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 13/58 - Session Exp_2025-06-23-v3/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 14/58 - Session Exp_2025-06-23-v4/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 15/58 - Session Exp_2025-06-24-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 16/58 - Session Exp_2025-06-24-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 17/58 - Session Exp_2025-06-24-v3/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 18/58 - Session Exp_2025-06-24-v4/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 19/58 - Session Exp_2025-06-26-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 20/58 - Session Exp_2025-06-26-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 21/58 - Session Exp_2025-06-26-v3/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 22/58 - Session Exp_2025-06-26-v4/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 23/58 - Session Exp_2025-06-27-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 24/58 - Session Exp_2025-06-27-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 25/58 - Session Exp_2025-06-27-v3/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 26/58 - Session Exp_2025-06-27-v4/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 27/58 - Session Exp_2025-06-30-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 28/58 - Session Exp_2025-06-30-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 29/58 - Session Exp_2025-06-30-v3/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 30/58 - Session Exp_2025-06-30-v4/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 31/58 - Session Exp_2025-07-01-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 32/58 - Session Exp_2025-07-01-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 33/58 - Session Exp_2025-07-01-v3/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 34/58 - Session Exp_2025-07-01-v4/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 35/58 - Session Exp_2025-07-02-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 36/58 - Session Exp_2025-07-02-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 37/58 - Session Exp_2025-07-02-v3/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 38/58 - Session Exp_2025-07-02-v4/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 39/58 - Session Exp_2025-07-03-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 40/58 - Session Exp_2025-07-03-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 41/58 - Session Exp_2025-07-03-v3/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 42/58 - Session Exp_2025-07-03-v4/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 43/58 - Session Exp_2025-07-07-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 44/58 - Session Exp_2025-07-07-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 45/58 - Session Exp_2025-07-07-v3/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 46/58 - Session Exp_2025-07-07-v4/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 47/58 - Session Exp_2025-07-09-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 48/58 - Session Exp_2025-07-09-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 49/58 - Session Exp_2025-07-09-v3/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 50/58 - Session Exp_2025-07-09-v4/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 51/58 - Session Exp_2025-07-10-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 52/58 - Session Exp_2025-07-10-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 53/58 - Session Exp_2025-07-10-v3/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 54/58 - Session Exp_2025-07-10-v4/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 55/58 - Session Exp_2025-07-11-v1/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 56/58 - Session Exp_2025-07-11-v2/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 57/58 - Session Exp_2025-07-11-v3/E9AD0E7DCC2B/\n",
      "========================================\n",
      "Dataset 58/58 - Session Exp_2025-07-11-v4/E9AD0E7DCC2B/\n",
      "========================================\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "trainer = Trainer.TremorModelTrainer(config, subject=\"Hunmin\")\n",
    "feature_acc = []\n",
    "\n",
    "for idx, f in enumerate(feature_idx):\n",
    "    X_train = X_train_stacked[:, :, f:f+1, :]\n",
    "    X_test = X_test_stacked[:, :, f:f+1, :]\n",
    "\n",
    "    X_train = np.squeeze(X_train, axis=-1)  # Remove last dim â†’ (100000, 4, 1)\n",
    "    X_test = np.squeeze(X_test, axis=-1)\n",
    "\n",
    "    print(X_train.shape, X_test.shape)\n",
    "\n",
    "    acc, _ = trainer.train_multiple_dataset(X_train, y_train_stacked, X_test, y_test_stacked)\n",
    "    feature_acc.append(acc)\n",
    "    print(\"\\n\")"
   ],
   "id": "a6b8f87d592037fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "96c13c2b4fc88a89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "54f1fea4ebd3e53f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6c6222c6a20cd192"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4c8088cd07dc70c4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
