{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.append('../../Share/')\n",
    "import Model\n",
    "\n",
    "def random_downsample_Num(X, y=None, n_keep=None, random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    if n_keep is None or n_keep > n_samples:\n",
    "        raise ValueError(f\"n_keep must be between 1 and {n_samples}, got {n_keep}\")\n",
    "\n",
    "    idx_keep = np.random.choice(n_samples, size=n_keep, replace=False)\n",
    "    X_down = X[idx_keep]\n",
    "\n",
    "    if y is not None:\n",
    "        y_down = y[idx_keep]\n",
    "        return X_down, y_down\n",
    "    else:\n",
    "        return X_down"
   ],
   "id": "f8f65a37150ac35b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Subject 1 버리기 + use only subject 2 and 3",
   "id": "eb849917a5e96f01"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-22T15:43:47.137699Z",
     "start_time": "2025-08-22T15:43:42.128823Z"
    }
   },
   "source": [
    "path = 'C:/Users/hml76/Desktop/Jupyter/Federated Prototype Learning/Dataset/Ours_cleaned/'\n",
    "fname = os.listdir(path)\n",
    "\n",
    "subjects = {\n",
    "    \"subject1\": {\"X\": [], \"Y\": []},\n",
    "    \"subject2\": {\"X\": [], \"Y\": []},\n",
    "    \"subject3\": {\"X\": [], \"Y\": []},\n",
    "}\n",
    "\n",
    "for f in fname:\n",
    "    for i in range(10):\n",
    "        X = np.array(pd.read_csv(path + f'{f}/rep{i}_X.csv'))\n",
    "        y = np.array(pd.read_csv(path + f'{f}/rep{i}_Y.csv'))\n",
    "\n",
    "        # shuffle\n",
    "        #indices = np.random.permutation(len(X))\n",
    "        #X, y = X[indices], y[indices]\n",
    "\n",
    "        # convert one-hot to integer labels\n",
    "        y_int = np.argmax(y, axis=1)\n",
    "        num_classes = np.max(y_int) + 1\n",
    "\n",
    "        # example rule to assign data to subject dict\n",
    "        if \"subject1\" in f:\n",
    "            subjects[\"subject1\"][\"X\"].append(X)\n",
    "            subjects[\"subject1\"][\"Y\"].append(y_int)\n",
    "        elif \"subject2\" in f:\n",
    "            subjects[\"subject2\"][\"X\"].append(X)\n",
    "            subjects[\"subject2\"][\"Y\"].append(y_int)\n",
    "        elif \"subject3\" in f:\n",
    "            subjects[\"subject3\"][\"X\"].append(X)\n",
    "            subjects[\"subject3\"][\"Y\"].append(y_int)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. K1/4/7/10 initialization (저걸로 학습시키기) + Test on rest of the subjects\n",
    "2."
   ],
   "id": "179a82d9c9168406"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Subject 2",
   "id": "edc2f3b06854b888"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for t in range(num_trials):\n",
    "    X, y = X_lst[t].reshape(-1,16,14,1), y_lst[t]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "    feature_set = 14\n",
    "    print(pd.Series(y_train).value_counts())"
   ],
   "id": "32bc0c9e83ad2f90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:30:18.407184Z",
     "start_time": "2025-08-22T16:30:18.402742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Baseline training on subjects\n",
    "def feature_analysis(X_lst, y_lst):\n",
    "    num_trials = len(X_lst)\n",
    "    all_acc = []\n",
    "    for t in range(num_trials):\n",
    "        X, y = X_lst[t].reshape(-1,16,14,1), y_lst[t]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "        feature_set = 14\n",
    "        feat_acc = []\n",
    "\n",
    "        for f in range(feature_set):\n",
    "            X_train_f = X_train[:,:,f,:]\n",
    "            X_test_f = X_test[:,:,f,:]\n",
    "            #model = Model.Original_model(input_shape=X_train.shape[1:], num_class=6)\n",
    "            model = Model.Original_model_1DCNN(input_size=X_train_f.shape[1:], num_class=6)\n",
    "\n",
    "            history, _ = Model.Train_model(model, X_train_f, y_train, X_test_f, y_test, set_epoch=50, set_batch_size=128, Model_name=None, set_verbose=False, save_model_set=False)\n",
    "            #plt.plot(history.history['val_accuracy'])\n",
    "            #plt.plot(history.history['accuracy'])\n",
    "            #plt.show()\n",
    "\n",
    "            print(f\"\\tTrial {t+1}/{num_trials}/feat{f} | Val Acc: {np.max(history.history['val_accuracy'])}\")\n",
    "            feat_acc.append(np.max(history.history['val_accuracy']))\n",
    "        all_acc.append(feat_acc)\n",
    "\n",
    "    return all_acc"
   ],
   "id": "f4fbd915b16fb8fa",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_lst2, y_lst2 = subjects[\"subject2\"][\"X\"], subjects[\"subject2\"][\"Y\"]\n",
    "all_acc_S2 = feature_analysis(X_lst, y_lst)"
   ],
   "id": "510b3d018f446715"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "807379cc84abbd7b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T17:20:31.002747Z",
     "start_time": "2025-08-22T17:20:30.998561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_lst2, y_lst2 = subjects[\"subject2\"][\"X\"], subjects[\"subject2\"][\"Y\"]\n",
    "all_acc_S2 = feature_analysis(X_lst, y_lst)\n",
    "#np.mean(all_acc, axis=1)\n",
    "#[0.54582531, 0.59289471, 0.71110999, 0.68362534, 0.76991238, 0.49386236, 0.49553254, 0.48481364, 0.5051527 , 0.39519543]# = ave - subject 2"
   ],
   "id": "adca4a4e5398a87e",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T17:20:40.193231Z",
     "start_time": "2025-08-22T17:20:40.190217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_lst3, y_lst3 = subjects[\"subject3\"][\"X\"], subjects[\"subject3\"][\"Y\"]\n",
    "all_acc_S3 = feature_analysis(X_lst, y_lst)\n",
    "#[0.58912348, 0.59857687, 0.67890562, 0.50030979, 0.45444015, 0.53214064, 0.57473667, 0.62291515, 0.49060753, 0.47509458]"
   ],
   "id": "dd640174d8b03ac7",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T17:17:32.730512Z",
     "start_time": "2025-08-22T17:17:32.725514Z"
    }
   },
   "cell_type": "code",
   "source": "np.mean(all_acc_S3, axis=1)",
   "id": "cbfaeaada88d01b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58912348, 0.59857687, 0.67890562, 0.50030979, 0.45444015,\n",
       "       0.53214064, 0.57473667, 0.62291515, 0.49060753, 0.47509458])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inter-session",
   "id": "70c6d5b0b960e210"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T17:24:45.038362Z",
     "start_time": "2025-08-22T17:24:45.033027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def inter_session_run(X_lst, y_lst, feature_idx):\n",
    "    f = feature_idx\n",
    "\n",
    "    num_trials = len(X_lst)\n",
    "    all_acc_K = []\n",
    "\n",
    "    for t in [1, 4, 7, 9]:\n",
    "        # Train split\n",
    "        X_train = [X_lst[i].reshape(-1, 16, 14, 1) for i in range(t)]\n",
    "        X_train = np.concatenate(X_train, axis=0)\n",
    "\n",
    "        y_train = [y_lst[i] for i in range(t)]\n",
    "        y_train = np.concatenate(y_train, axis=0)\n",
    "\n",
    "        # Test split\n",
    "        X_test = [X_lst[i].reshape(-1, 16, 14, 1) for i in range(t, len(X_lst))]\n",
    "        X_test = np.concatenate(X_test, axis=0)\n",
    "\n",
    "        y_test = [y_lst[i] for i in range(t, len(y_lst))]\n",
    "        y_test = np.concatenate(y_test, axis=0)\n",
    "        print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "        X_train_f, X_test_f = X_train[:,:,f,:], X_test[:,:,f,:]\n",
    "        X_test_f, y_test = random_downsample_Num(X_test_f, y_test, n_keep=1000, random_state=42)\n",
    "\n",
    "        model = Model.Original_model_1DCNN(input_size=X_train_f.shape[1:], num_class=6)\n",
    "        history, _ = Model.Train_model(model, X_train_f, y_train, X_test_f, y_test, set_epoch=50, set_batch_size=128, Model_name=None, set_verbose=False, save_model_set=False)\n",
    "\n",
    "        print(f\"\\tTrial {t+1}/{num_trials}/feat{f} | Val Acc: {np.max(history.history['val_accuracy'])}\")\n",
    "        all_acc_K.append(np.max(history.history['val_accuracy']))\n",
    "    return all_acc_K"
   ],
   "id": "6f72d5ec4ca1ba20",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T17:30:55.856356Z",
     "start_time": "2025-08-22T17:25:15.806882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_acc_K_S2 = inter_session_run(X_lst2, y_lst2, feature_idx=2)\n",
    "all_acc_K_S3 = inter_session_run(X_lst3, y_lst3, feature_idx=2)\n",
    "#all_acc_K"
   ],
   "id": "6398b2237a37551d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6303, 16, 14, 1) (6303,) (64036, 16, 14, 1) (64036,)\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 52.17%\n",
      "Maximum validation accuracy : 31.5%\n",
      "\tTrial 2/10/feat2 | Val Acc: 0.3149999976158142\n",
      "(26399, 16, 14, 1) (26399,) (43940, 16, 14, 1) (43940,)\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 55.96%\n",
      "Maximum validation accuracy : 27.0%\n",
      "\tTrial 5/10/feat2 | Val Acc: 0.27000001072883606\n",
      "(48077, 16, 14, 1) (48077,) (22262, 16, 14, 1) (22262,)\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 51.0%\n",
      "Maximum validation accuracy : 26.8%\n",
      "\tTrial 8/10/feat2 | Val Acc: 0.2680000066757202\n",
      "(63084, 16, 14, 1) (63084,) (7255, 16, 14, 1) (7255,)\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 47.01%\n",
      "Maximum validation accuracy : 27.5%\n",
      "\tTrial 10/10/feat2 | Val Acc: 0.2750000059604645\n",
      "(8251, 16, 14, 1) (8251,) (72126, 16, 14, 1) (72126,)\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 51.45%\n",
      "Maximum validation accuracy : 26.2%\n",
      "\tTrial 2/10/feat2 | Val Acc: 0.2619999945163727\n",
      "(32212, 16, 14, 1) (32212,) (48165, 16, 14, 1) (48165,)\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 52.37%\n",
      "Maximum validation accuracy : 32.8%\n",
      "\tTrial 5/10/feat2 | Val Acc: 0.328000009059906\n",
      "(56777, 16, 14, 1) (56777,) (23600, 16, 14, 1) (23600,)\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 46.43%\n",
      "Maximum validation accuracy : 46.6%\n",
      "\tTrial 8/10/feat2 | Val Acc: 0.4659999907016754\n",
      "(72447, 16, 14, 1) (72447,) (7930, 16, 14, 1) (7930,)\n",
      "Start Training (total epochs: 50)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[31]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m all_acc_K_S2 = inter_session_run(X_lst2, y_lst2, feature_idx=\u001B[32m2\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m all_acc_K_S3 = \u001B[43minter_session_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_lst3\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_lst3\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_idx\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m#all_acc_K\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[30]\u001B[39m\u001B[32m, line 27\u001B[39m, in \u001B[36minter_session_run\u001B[39m\u001B[34m(X_lst, y_lst, feature_idx)\u001B[39m\n\u001B[32m     24\u001B[39m X_test_f, y_test = random_downsample_Num(X_test_f, y_test, n_keep=\u001B[32m1000\u001B[39m, random_state=\u001B[32m42\u001B[39m)\n\u001B[32m     26\u001B[39m model = Model.Original_model_1DCNN(input_size=X_train_f.shape[\u001B[32m1\u001B[39m:], num_class=\u001B[32m6\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m history, _ = \u001B[43mModel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mTrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_f\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test_f\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mset_epoch\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mset_batch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m128\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mModel_name\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mset_verbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_model_set\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m     29\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[33mTrial \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt+\u001B[32m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_trials\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m/feat\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mf\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m | Val Acc: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnp.max(history.history[\u001B[33m'\u001B[39m\u001B[33mval_accuracy\u001B[39m\u001B[33m'\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     30\u001B[39m all_acc_K.append(np.max(history.history[\u001B[33m'\u001B[39m\u001B[33mval_accuracy\u001B[39m\u001B[33m'\u001B[39m]))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\MindForce\\github\\V6 Paper\\Offline gesture - Subsection 1 - Amputee\\../../Share\\Model.py:174\u001B[39m, in \u001B[36mTrain_model\u001B[39m\u001B[34m(model, X_train, y_train, X_test, y_test, set_epoch, set_batch_size, Model_name, set_verbose, save_model_set)\u001B[39m\n\u001B[32m    171\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mFinish Training! (Model is saved)\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    173\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:   \u001B[38;5;66;03m####  Don't save\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m174\u001B[39m     history = \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    175\u001B[39m \u001B[43m        \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    176\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    177\u001B[39m \u001B[43m        \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mset_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    178\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mset_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    179\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlr_schedule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mearly_stop\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    180\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m#callbacks=[lr_schedule],\u001B[39;49;00m\n\u001B[32m    181\u001B[39m \u001B[43m        \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    182\u001B[39m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[43mset_verbose\u001B[49m\n\u001B[32m    183\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    184\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mFinish Training! (Model is NOT saved)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    186\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mMaximum training accuracy : \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnp.round(\u001B[38;5;28mfloat\u001B[39m(np.max(history.history[\u001B[33m'\u001B[39m\u001B[33maccuracy\u001B[39m\u001B[33m'\u001B[39m])\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[32m100\u001B[39m),\u001B[38;5;250m \u001B[39m\u001B[32m2\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m%\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\TNSE-R1\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    115\u001B[39m filtered_tb = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    116\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m117\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    119\u001B[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\TNSE-R1\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:376\u001B[39m, in \u001B[36mTensorFlowTrainer.fit\u001B[39m\u001B[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[39m\n\u001B[32m    374\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m epoch_iterator.catch_stop_iteration():\n\u001B[32m    375\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator:\n\u001B[32m--> \u001B[39m\u001B[32m376\u001B[39m         \u001B[43mcallbacks\u001B[49m\u001B[43m.\u001B[49m\u001B[43mon_train_batch_begin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    377\u001B[39m         logs = \u001B[38;5;28mself\u001B[39m.train_function(iterator)\n\u001B[32m    378\u001B[39m         callbacks.on_train_batch_end(step, logs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\TNSE-R1\\.venv\\Lib\\site-packages\\keras\\src\\callbacks\\callback_list.py:147\u001B[39m, in \u001B[36mCallbackList.on_train_batch_begin\u001B[39m\u001B[34m(self, batch, logs)\u001B[39m\n\u001B[32m    144\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m callback \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.callbacks:\n\u001B[32m    145\u001B[39m         callback.on_epoch_end(epoch, logs)\n\u001B[32m--> \u001B[39m\u001B[32m147\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mon_train_batch_begin\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch, logs=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m    148\u001B[39m     logs = python_utils.pythonify_logs(logs)\n\u001B[32m    149\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m callback \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.callbacks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:30:18.343329Z",
     "start_time": "2025-08-22T16:25:45.105083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Baseline training on subject2\n",
    "X_lst, y_lst = subjects[\"subject2\"][\"X\"], subjects[\"subject2\"][\"Y\"]\n",
    "num_trials = len(X_lst)\n",
    "all_acc_K = []\n",
    "\n",
    "for t in [1, 4, 7, 9]:\n",
    "    X_train = [X_lst[i].reshape(-1, 16, 14, 1) for i in range(t)]\n",
    "    X_train = np.concatenate(X_train, axis=0)\n",
    "    y_train = [y_lst[i] for i in range(t)]\n",
    "    y_train = np.concatenate(y_train, axis=0)\n",
    "\n",
    "    X_test = [X_lst[i].reshape(-1, 16, 14, 1) for i in range(t, len(X_lst))]\n",
    "    X_test = np.concatenate(X_test, axis=0)\n",
    "    y_test = [y_lst[i] for i in range(t, len(y_lst))]\n",
    "    y_test = np.concatenate(y_test, axis=0)\n",
    "\n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "    #f = 4\n",
    "    #X_train_f, X_test_f = X_train[:,:,f,:], X_test[:,:,f,:]\n",
    "    X_test, y_test = random_downsample_Num(X_test, y_test, n_keep=1000, random_state=42)\n",
    "\n",
    "    model = Model.Original_model(input_shape=X_train.shape[1:], num_class=6)\n",
    "    history, _ = Model.Train_model(model, X_train, y_train, X_test, y_test, set_epoch=50, set_batch_size=128, Model_name=None, set_verbose=False, save_model_set=False)\n",
    "\n",
    "    print(f\"\\tTrial {t+1}/{num_trials}/feat{f} | Val Acc: {np.max(history.history['val_accuracy'])}\")\n",
    "    all_acc_K.append(np.max(history.history['val_accuracy']))\n",
    "all_acc_K"
   ],
   "id": "90ccbc2c349df18e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6303, 16, 14, 1) (6303,) (64036, 16, 14, 1) (64036,)\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 53.43%\n",
      "Maximum validation accuracy : 22.5%\n",
      "\tTrial 2/10/feat4 | Val Acc: 0.22499999403953552\n",
      "(26399, 16, 14, 1) (26399,) (43940, 16, 14, 1) (43940,)\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 59.92%\n",
      "Maximum validation accuracy : 24.3%\n",
      "\tTrial 5/10/feat4 | Val Acc: 0.24300000071525574\n",
      "(48077, 16, 14, 1) (48077,) (22262, 16, 14, 1) (22262,)\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 50.81%\n",
      "Maximum validation accuracy : 34.3%\n",
      "\tTrial 8/10/feat4 | Val Acc: 0.34299999475479126\n",
      "(63084, 16, 14, 1) (63084,) (7255, 16, 14, 1) (7255,)\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 49.41%\n",
      "Maximum validation accuracy : 34.6%\n",
      "\tTrial 10/10/feat4 | Val Acc: 0.34599998593330383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[np.float64(0.22499999403953552),\n",
       " np.float64(0.24300000071525574),\n",
       " np.float64(0.34299999475479126),\n",
       " np.float64(0.34599998593330383)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:30:18.372861Z",
     "start_time": "2025-08-22T16:30:18.368131Z"
    }
   },
   "cell_type": "code",
   "source": "all_acc_K",
   "id": "8e7b57d2dd4a8976",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.22499999403953552),\n",
       " np.float64(0.24300000071525574),\n",
       " np.float64(0.34299999475479126),\n",
       " np.float64(0.34599998593330383)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9ffb0602ce749da"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
