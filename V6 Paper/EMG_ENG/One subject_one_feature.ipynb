{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy, os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../Share/')\n",
    "sys.path.append('../../Share/Manual_processing/')\n",
    "import baseline, config, Model, utils, Same_with_MATLAB, Feature_info\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def restore_labels(mat, labels_windowed):\n",
    "\n",
    "    original_length = mat['Data_ADC'].shape[1]\n",
    "    win_size = 1000 # 200ms 10\n",
    "    win_step = 50\n",
    "    #valid_length = original_length - 2 * 60\n",
    "\n",
    "    label_full = np.zeros(original_length, dtype=labels_windowed.dtype) # 복원될 시계열 레이블 (원본 길이)\n",
    "\n",
    "    # 슬라이딩 윈도우 인덱스 따라 레이블 채워넣기\n",
    "    for i, label in enumerate(labels_windowed):\n",
    "        start = 60 + i * win_step\n",
    "        end = start + win_size\n",
    "        if end <= original_length - 60:\n",
    "            label_full[start:end] = label\n",
    "\n",
    "    return label_full\n",
    "\n",
    "\n",
    "def filtering_zero(X, y, erase_label):\n",
    "    # 1. erase_label 제거\n",
    "    keep_indices = y != erase_label\n",
    "    X = X[keep_indices]\n",
    "    y = y[keep_indices]\n",
    "\n",
    "    # 2. erase_label보다 큰 값은 1씩 감소\n",
    "    y = np.where(y > erase_label, y - 1, y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def vis_graph(history):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def heatmap_confusion_matrix(X_test, y_test, model):\n",
    "    # Predict class labels on the test set\n",
    "    y_pred_probs = model.predict(X_test, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)  # convert softmax probs to predicted class\n",
    "    y_true = y_test\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(np.max(y_test)+1), yticklabels=range(np.max(y_test)+1))\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def balance_data(X, y):\n",
    "    # Count samples per class\n",
    "    class_counts = Counter(y)\n",
    "    min_count = min(class_counts.values())  # target: balance all to minority count\n",
    "\n",
    "    indices_list = []\n",
    "\n",
    "    for label in sorted(class_counts.keys()):\n",
    "        label_indices = np.where(y == label)[0]\n",
    "        selected_indices = np.random.choice(label_indices, size=min_count, replace=False)\n",
    "        indices_list.extend(selected_indices)\n",
    "\n",
    "    # Shuffle all selected indices\n",
    "    balanced_indices = np.random.permutation(indices_list)\n",
    "\n",
    "    # Subset the data\n",
    "    X_balanced = X[balanced_indices]\n",
    "    y_balanced = y[balanced_indices]\n",
    "\n",
    "    return X_balanced, y_balanced"
   ],
   "id": "23ed3ec69a7ccf76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def return_X_y(path, balance):\n",
    "    fs, lower_cutoff, upper_cutoff = Feature_info.fs, Feature_info.lower_cutoff, Feature_info.upper_cutoff\n",
    "    # fs, lower_cutoff, upper_cutoff = Feature_info.fs, 1, 300\n",
    "    filter_b, filter_a = Same_with_MATLAB.cheby2(4, 30, [lower_cutoff / (fs/2), upper_cutoff / (fs/2)], btype='bandpass')\n",
    "\n",
    "    data_per_class_files = os.listdir(path)\n",
    "    X, y = [], []\n",
    "\n",
    "    for cls in data_per_class_files:\n",
    "        input_path = path+cls+'/'\n",
    "        files = os.listdir(input_path)\n",
    "        mat = scipy.io.loadmat(input_path+files[0])\n",
    "        label = mat['Data_Cls'].reshape(-1)  # shape: (1, 1729)\n",
    "\n",
    "        feat_mean = np.tile(Feature_info.feat_mean_lst, (4, 1))\n",
    "        feat_std = np.tile(Feature_info.feat_std_lst, (4, 1))\n",
    "\n",
    "        mapped_label = np.where(label == 0, 0, int(cls))\n",
    "        restored_label = restore_labels(mat, mapped_label)\n",
    "\n",
    "        #print(mat['Data_ADC'].shape, mat['Data_Cls'].shape, restored_label.shape)\n",
    "        extractor = Same_with_MATLAB.EMGFeatureExtractor(feat_mean, feat_std, filter_b, filter_a, Norm_bool=True, num_feature_set=14) #I tried 23, but not so good\n",
    "        extractor.buffer = mat['Data_ADC']\n",
    "        #1000, 50 = winsize and winstep\n",
    "        features, labels = extractor.extract_features_with_labels(win_size=1000, win_step=50, feat_exclude=25, filtering=False, restored_label=restored_label)\n",
    "\n",
    "        features = np.transpose(features, (2, 0, 1))  # shape: (1729, 4, 14)\n",
    "        X.append(features)\n",
    "        y.append(labels)\n",
    "        #print(features.shape, labels.shape)\n",
    "\n",
    "    X_train = np.concatenate(X, axis=0)\n",
    "    y_train = np.concatenate(y, axis=0)\n",
    "    X_train = X_train[:, :, :, np.newaxis]\n",
    "    #print(pd.Series(y_train).value_counts())\n",
    "    print(X_train.shape, y_train.shape)\n",
    "\n",
    "    if balance:\n",
    "        X_train, y_train = balance_data(X_train, y_train)\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "\n",
    "def train_model_feature_wise(X_train, y_train, X_test, y_test, num_channels):\n",
    "    X_train, y_train = filtering_zero(X_train, y_train, erase_label=0)\n",
    "    X_test, y_test = filtering_zero(X_test, y_test, erase_label=0)\n",
    "    ACC_lst = []\n",
    "    feature_idx = 2\n",
    "    #for feature_idx in [2, 10]:\n",
    "    One_X_train = X_train[:, :, feature_idx, :]\n",
    "    One_X_test = X_test[:, :, feature_idx, :]\n",
    "\n",
    "    model = Model.Original_model_1DCNN(One_X_train.shape[1:], num_class=np.max(y_train)+1)\n",
    "\n",
    "    history, model = Model.Train_model(\n",
    "        model, One_X_train, y_train, One_X_test, y_test,\n",
    "        set_epoch=200, set_batch_size=256, Model_name='V0',\n",
    "        set_verbose=False, save_model_set=False\n",
    "    )\n",
    "    #ACC_lst.append(np.max(history.history['val_accuracy']))\n",
    "\n",
    "\n",
    "def run(subject, modality, num_channels):\n",
    "    if modality == 'EMG': bluetooth_id = 'E8DD80E550BB'\n",
    "    elif modality == 'ENG': bluetooth_id = 'E9AD0E7DCC2B'\n",
    "    else:\n",
    "        print(\"Modality should be EMG or ENG\")\n",
    "        return\n",
    "\n",
    "    X_train, y_train = return_X_y(path = base_path+f'{subject}/{modality}_v1/{bluetooth_id}/raw/', balance=True)\n",
    "    X_test, y_test = return_X_y(path = base_path+f'{subject}/{modality}_v2/{bluetooth_id}/raw/', balance=True)\n",
    "    result1 = train_model_feature_wise(X_train, y_train, X_test, y_test, num_channels)\n",
    "\n",
    "    X_train, y_train = return_X_y(path = base_path+f'{subject}/{modality}_v2/{bluetooth_id}/raw/', balance=True)\n",
    "    X_test, y_test = return_X_y(path = base_path+f'{subject}/{modality}_v1/{bluetooth_id}/raw/', balance=True)\n",
    "    result2 = train_model_feature_wise(X_train, y_train, X_test, y_test, num_channels)\n",
    "\n",
    "    return np.mean([result1, result2])"
   ],
   "id": "81ada91a58c6a416"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "base_path = 'C:/Users/hml76/PycharmProjects/MindForce/data/EMG_ENG/'\n",
    "acc_all_ch4, acc_all_ch3, acc_all_ch2, acc_all_ch1 = [], [], [], []"
   ],
   "id": "bb73a3ed29f4217c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#run(subject='Hunmin', modality='EMG', num_channels=4) #19, 19",
   "id": "f5f9ab5f1fb4b182"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "SUB = 'Hunmin'\n",
    "result = run(subject=SUB, modality='ENG', num_channels=4)  #18,15\n",
    "acc_all_ch4.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=3)  #18,15\n",
    "acc_all_ch3.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=2)  #18,15\n",
    "acc_all_ch2.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=1)  #18,15\n",
    "acc_all_ch1.append(result)"
   ],
   "id": "2b6f21c7c7e19271"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Byeongchan",
   "id": "f965a62c03c97f9c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "SUB = 'Byeongchan'\n",
    "result = run(subject=SUB, modality='ENG', num_channels=4)  #18,15\n",
    "acc_all_ch4.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=3)  #18,15\n",
    "acc_all_ch3.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=2)  #18,15\n",
    "acc_all_ch2.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=1)  #18,15\n",
    "acc_all_ch1.append(result)"
   ],
   "id": "752804fbbb10ff12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "572114bcc7878271"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "SUB = 'Hongjun'\n",
    "result = run(subject=SUB, modality='ENG', num_channels=4)  #18,15\n",
    "acc_all_ch4.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=3)  #18,15\n",
    "acc_all_ch3.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=2)  #18,15\n",
    "acc_all_ch2.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=1)  #18,15\n",
    "acc_all_ch1.append(result)"
   ],
   "id": "6f9a5b33e9c2845f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a552fd233935a458"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "SUB = 'Jongin'\n",
    "result = run(subject=SUB, modality='ENG', num_channels=4)  #18,15\n",
    "acc_all_ch4.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=3)  #18,15\n",
    "acc_all_ch3.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=2)  #18,15\n",
    "acc_all_ch2.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=1)  #18,15\n",
    "acc_all_ch1.append(result)"
   ],
   "id": "4533003e3ad580b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "37b999f5cba39e45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "SUB = 'Youngchul'\n",
    "result = run(subject=SUB, modality='ENG', num_channels=4)  #18,15\n",
    "acc_all_ch4.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=3)  #18,15\n",
    "acc_all_ch3.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=2)  #18,15\n",
    "acc_all_ch2.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=1)  #18,15\n",
    "acc_all_ch1.append(result)"
   ],
   "id": "2dced5796df8f805"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bd2999c3e38e342d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "SUB = 'Harold'\n",
    "result = run(subject=SUB, modality='ENG', num_channels=4)  #18,15\n",
    "acc_all_ch4.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=3)  #18,15\n",
    "acc_all_ch3.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=2)  #18,15\n",
    "acc_all_ch2.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=1)  #18,15\n",
    "acc_all_ch1.append(result)"
   ],
   "id": "fd5fe43c85f2deff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "52f473f16bf5834e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "SUB = 'Carlson'\n",
    "result = run(subject=SUB, modality='ENG', num_channels=4)  #18,15\n",
    "acc_all_ch4.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=3)  #18,15\n",
    "acc_all_ch3.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=2)  #18,15\n",
    "acc_all_ch2.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=1)  #18,15\n",
    "acc_all_ch1.append(result)"
   ],
   "id": "ac88ba35398148"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a387ce94aeafc5bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "SUB = 'Minjeong'\n",
    "result = run(subject=SUB, modality='ENG', num_channels=4)  #18,15\n",
    "acc_all_ch4.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=3)  #18,15\n",
    "acc_all_ch3.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=2)  #18,15\n",
    "acc_all_ch2.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=1)  #18,15\n",
    "acc_all_ch1.append(result)"
   ],
   "id": "ca3839c76230c133"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f52282aae9e3403a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "SUB = 'Xianyu'\n",
    "result = run(subject=SUB, modality='ENG', num_channels=4)  #18,15\n",
    "acc_all_ch4.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=3)  #18,15\n",
    "acc_all_ch3.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=2)  #18,15\n",
    "acc_all_ch2.append(result)\n",
    "\n",
    "result = run(subject=SUB, modality='ENG', num_channels=1)  #18,15\n",
    "acc_all_ch1.append(result)"
   ],
   "id": "3968b5baeda4637"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9aa17f92a16cea8c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
