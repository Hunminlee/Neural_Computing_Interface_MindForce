{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T19:05:35.733537Z",
     "start_time": "2025-06-30T19:05:34.538029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "baseline1_csv_path = 'C:/Users/hml76/PycharmProjects/Tremor_project_local/NCI_mindforce/github/Results/Baseline_results_train_with_1data.csv'\n",
    "baseline2_csv_path = 'C:/Users/hml76/PycharmProjects/Tremor_project_local/NCI_mindforce/github/Results/Baseline_results_train_with_10data.csv'\n",
    "baseline3_csv_path = 'C:/Users/hml76/PycharmProjects/Tremor_project_local/NCI_mindforce/github/Results/Baseline_results_train_with_14data.csv'\n",
    "baseline4_csv_path = 'C:/Users/hml76/PycharmProjects/Tremor_project_local/NCI_mindforce/github/Results/Baseline_results_train_with_18data.csv'\n",
    "baseline5_csv_path = 'C:/Users/hml76/PycharmProjects/Tremor_project_local/NCI_mindforce/github/Results/Baseline_results_train_with_22data.csv'\n",
    "\n",
    "baseline_K = ['1', '10', '14', '18', '22']\n",
    "baselines = [baseline1_csv_path, baseline2_csv_path,  baseline3_csv_path,  baseline4_csv_path, baseline5_csv_path]"
   ],
   "id": "d97a4eda5c0ae2da",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Baseline: Training datasets and store\n",
    "- Time 1 (1 day)\n",
    "- Time 10 (3 days)\n",
    "- Time 14 (4 days)\n",
    "- Time 18 (5 days)\n",
    "- Time 22 (6 days)"
   ],
   "id": "1450ab5a6650964"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-30T19:05:36.003188Z",
     "start_time": "2025-06-30T19:05:35.998357Z"
    }
   },
   "source": [
    "'''import Test_without_Training\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for K in [1, 10, 14, 18, 22]:\n",
    "        trainer = Test_without_Training.TremorModelTrainer(config, subject=\"Hunmin\")\n",
    "        trainer.run_all_sessions_training_K_data(K)\n",
    "        df = trainer.save_results(f'../Results/Baseline_results_train_with_{K}data.csv')'''\n",
    "# 저장해놨어서 굳이 안돌려도 됨"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import Test_without_Training\\n\\nif __name__ == \"__main__\":\\n    for K in [1, 10, 14, 18, 22]:\\n        trainer = Test_without_Training.TremorModelTrainer(config, subject=\"Hunmin\")\\n        trainer.run_all_sessions_training_K_data(K)\\n        df = trainer.save_results(f\\'../Results/Baseline_results_train_with_{K}data.csv\\')'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Training from scratch in every data\n",
    "- Performance should be high\n",
    "- Objective"
   ],
   "id": "617e3524e555e3bc"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-30T19:05:36.013585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import Training_from_scratch\n",
    "\n",
    "prog_trainer = Training_from_scratch.ProgressiveTrainer(config, subject=\"Hunmin\")\n",
    "Init_acc_all, Prev_acc_all, Trained_acc_all = prog_trainer.run(plot_learning_curve=False)\n",
    "prog_trainer.plot_results(baselines, baseline_K)\n",
    "\n",
    "for idx, x in enumerate([Init_acc_all, Prev_acc_all, Trained_acc_all]):\n",
    "    if idx==0:\n",
    "        print(f\"Average of acc without training anything (should be random): {np.mean(x)*100:.2f}%\")\n",
    "    elif idx==1:\n",
    "        print(f\"Average of acc using previous test data after training: {np.mean(x)*100:.2f}%\")\n",
    "    elif idx==2:\n",
    "        print(f\"Average of acc using current test data after training: {np.mean(x)*100:.2f}%\")\n",
    "for idx, b in enumerate(baselines):\n",
    "    print(f\"Baseline K-{baseline_K[idx]}: {float(np.mean(pd.read_csv(baselines[idx])['Accuracy'][int(baseline_K[idx]):])):.2f}%\")"
   ],
   "id": "c78761ed10a16497",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================\n",
      "Dataset 1/30 - Session Exp_2025-05-27/E8331D05289A/\n",
      "===========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 84.55%\n",
      "Maximum validation accuracy : 93.21%\n",
      "\n",
      "===========================================\n",
      "Dataset 2/30 - Session Exp_2025-06-18/E9AD0E7DCC2B/\n",
      "===========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 85.99%\n",
      "Maximum validation accuracy : 89.0%\n",
      "\n",
      "===========================================\n",
      "Dataset 3/30 - Session Exp_2025-06-20-v1/E9AD0E7DCC2B/\n",
      "===========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 86.45%\n",
      "Maximum validation accuracy : 92.9%\n",
      "\n",
      "===========================================\n",
      "Dataset 4/30 - Session Exp_2025-06-20-v2/E9AD0E7DCC2B/\n",
      "===========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 86.79%\n",
      "Maximum validation accuracy : 92.31%\n",
      "\n",
      "===========================================\n",
      "Dataset 5/30 - Session Exp_2025-06-20-v3/E9AD0E7DCC2B/\n",
      "===========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 87.3%\n",
      "Maximum validation accuracy : 92.04%\n",
      "\n",
      "===========================================\n",
      "Dataset 6/30 - Session Exp_2025-06-20-v4/E9AD0E7DCC2B/\n",
      "===========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 79.59%\n",
      "Maximum validation accuracy : 85.96%\n",
      "\n",
      "===========================================\n",
      "Dataset 7/30 - Session Exp_2025-06-20-v5/E9AD0E7DCC2B/\n",
      "===========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 85.96%\n",
      "Maximum validation accuracy : 93.9%\n",
      "\n",
      "===========================================\n",
      "Dataset 8/30 - Session Exp_2025-06-20-v6/E9AD0E7DCC2B/\n",
      "===========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 81.77%\n",
      "Maximum validation accuracy : 87.68%\n",
      "\n",
      "===========================================\n",
      "Dataset 9/30 - Session Exp_2025-06-20-v7/E9AD0E7DCC2B/\n",
      "===========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 79.8%\n",
      "Maximum validation accuracy : 88.91%\n",
      "\n",
      "===========================================\n",
      "Dataset 10/30 - Session Exp_2025-06-20-v8/E9AD0E7DCC2B/\n",
      "===========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 85.06%\n",
      "Maximum validation accuracy : 93.09%\n",
      "\n",
      "===========================================\n",
      "Dataset 11/30 - Session Exp_2025-06-23-v1/E9AD0E7DCC2B/\n",
      "===========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 86.78%\n",
      "Maximum validation accuracy : 93.79%\n",
      "\n",
      "===========================================\n",
      "Dataset 12/30 - Session Exp_2025-06-23-v2/E9AD0E7DCC2B/\n",
      "===========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 86.37%\n",
      "Maximum validation accuracy : 92.69%\n",
      "\n",
      "===========================================\n",
      "Dataset 13/30 - Session Exp_2025-06-23-v3/E9AD0E7DCC2B/\n",
      "===========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 85.09%\n",
      "Maximum validation accuracy : 93.12%\n",
      "\n",
      "===========================================\n",
      "Dataset 14/30 - Session Exp_2025-06-23-v4/E9AD0E7DCC2B/\n",
      "===========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 87.23%\n",
      "Maximum validation accuracy : 93.13%\n",
      "\n",
      "===========================================\n",
      "Dataset 15/30 - Session Exp_2025-06-24-v1/E9AD0E7DCC2B/\n",
      "===========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 86.87%\n",
      "Maximum validation accuracy : 93.36%\n",
      "\n",
      "===========================================\n",
      "Dataset 16/30 - Session Exp_2025-06-24-v2/E9AD0E7DCC2B/\n",
      "===========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 82.48%\n",
      "Maximum validation accuracy : 92.17%\n",
      "\n",
      "===========================================\n",
      "Dataset 17/30 - Session Exp_2025-06-24-v3/E9AD0E7DCC2B/\n",
      "===========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 84.94%\n",
      "Maximum validation accuracy : 89.84%\n",
      "\n",
      "===========================================\n",
      "Dataset 18/30 - Session Exp_2025-06-24-v4/E9AD0E7DCC2B/\n",
      "===========================================\n",
      "Start Training (total epochs: 50)...\n",
      "Finish Training! (Model is NOT saved)\n",
      "\n",
      "Maximum training accuracy : 86.3%\n",
      "Maximum validation accuracy : 92.73%\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Transfer Learning - Incremental : Model is cumulatively updated",
   "id": "1cbeceb6c96dfa57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import Transfer_Learning\n",
    "\n",
    "tl_trainer = Transfer_Learning.TransferLearningTrainer(config, subject=\"Hunmin\", increment_true_false=\"True\")\n",
    "Init_acc_all, Prev_acc_all, Trained_acc_all = tl_trainer.run(plot_learning_curve=False)   #True if want to see convergence for each session round\n",
    "tl_trainer.plot_results(baselines, baseline_K)\n",
    "\n",
    "for idx, x in enumerate([Init_acc_all, Prev_acc_all, Trained_acc_all]):\n",
    "    if idx==0:\n",
    "        print(f\"Average of acc without training this data (init; unseen) - incrementally trained model with previous datasets: {np.mean(x)*100:.2f}%\")\n",
    "    elif idx==1:\n",
    "        print(f\"Average of acc using previous test data after training (with increment): {np.mean(x)*100:.2f}%\")\n",
    "    elif idx==2:\n",
    "        print(f\"Average of acc using current test data after training (with increment): {np.mean(x)*100:.2f}%\")\n",
    "\n",
    "for idx, b in enumerate(baselines):\n",
    "    print(f\"Baseline K-{baseline_K[idx]}: {float(np.mean(pd.read_csv(baselines[idx])['Accuracy'][int(baseline_K[idx]):])):.2f}%\")"
   ],
   "id": "b04b8081ae41aa29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Few-shot Learning (MAML) adaptation",
   "id": "495b33d36f8abc55"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import Few_shot_Learning\n",
    "\n",
    "trainer = Few_shot_Learning.MAMLProgressiveTrainer(config, subject=\"Hunmin\", K_shot=10, query_size=100)\n",
    "Init_acc_all, Prev_acc_all, Trained_acc_all = trainer.run()\n",
    "trainer.plot_results(baselines, baseline_K)\n",
    "\n",
    "for idx, x in enumerate([Init_acc_all, Prev_acc_all, Trained_acc_all]):\n",
    "    if idx==0:\n",
    "        print(f\"Average of acc without training anything (should be random): {np.mean(x)*100:.2f}%\")\n",
    "    elif idx==1:\n",
    "        print(f\"Average of acc using previous test data after training: {np.mean(x)*100:.2f}%\")\n",
    "    elif idx==2:\n",
    "        print(f\"Average of acc using current test data after training: {np.mean(x)*100:.2f}%\")\n",
    "\n",
    "for idx, b in enumerate(baselines):\n",
    "    print(f\"Baseline K-{baseline_K[idx]}: {float(np.mean(pd.read_csv(baselines[idx])['Accuracy'][int(baseline_K[idx]):])):.2f}%\")"
   ],
   "id": "ff3564540412d3a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Continual Learning (EWC)",
   "id": "c64b1204d953f165"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import Continual_Learning_EWC_\n",
    "\n",
    "cl_trainer = Continual_Learning_EWC_.ContinualLearningTrainer(config, subject=\"Hunmin\")\n",
    "Init_acc_all, Prev_acc_all, Trained_acc_all = cl_trainer.run()\n",
    "cl_trainer.plot_results(baselines, baseline_K)\n",
    "\n",
    "for idx, x in enumerate([Init_acc_all, Prev_acc_all, Trained_acc_all]):\n",
    "    if idx==0:\n",
    "        print(f\"Average of acc without training this data (init; unseen): {np.mean(x)*100:.2f}%\")\n",
    "    elif idx==1:\n",
    "        print(f\"Average of acc using previous test data after training: {np.mean(x)*100:.2f}%\")\n",
    "    elif idx==2:\n",
    "        print(f\"Average of acc using current test data after training: {np.mean(x)*100:.2f}%\")\n",
    "\n",
    "for idx, b in enumerate(baselines):\n",
    "    print(f\"Baseline K-{baseline_K[idx]}: {float(np.mean(pd.read_csv(baselines[idx])['Accuracy'][1:])):.2f}%\")"
   ],
   "id": "4ea332f22dc718fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fdc745341966397d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
