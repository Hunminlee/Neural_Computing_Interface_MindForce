{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T17:58:33.757966Z",
     "start_time": "2025-07-09T17:58:33.508629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "from tensorflow.python.layers.normalization import normalization\n",
    "\n",
    "sys.path.append(\"../Share\")\n",
    "import config"
   ],
   "id": "df8dd3a912157c6e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Downsampling the Data_ADC, to synchronize Data_Cls\n",
    "2."
   ],
   "id": "b4e1fa8f28509758"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T17:58:36.404344Z",
     "start_time": "2025-07-09T17:58:35.766763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from scipy.signal import lfilter, medfilt\n",
    "from scipy.signal import hilbert\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class EMGFeatureExtractor:\n",
    "    def __init__(self, feat_mean, feat_std, filter_b, filter_a, Norm_bool):\n",
    "        self.feat_mean = feat_mean\n",
    "        self.feat_std = feat_std\n",
    "        self.filter_b = filter_b\n",
    "        self.filter_a = filter_a\n",
    "        self.buffer = None  # to be set externally\n",
    "        self.normalization = Norm_bool\n",
    "\n",
    "\n",
    "    def extract_features(self, win_size=600, win_step=120, feat_exclude=60):\n",
    "        buf = lfilter(self.filter_b, self.filter_a, self.buffer, axis=1)\n",
    "        nch, len_x = buf.shape\n",
    "        n_steps = (len_x - win_size) // win_step + 1\n",
    "\n",
    "        features = np.zeros((nch, 14, n_steps))\n",
    "        for i in range(n_steps):\n",
    "            x = buf[:, i*win_step:i*win_step+win_size]\n",
    "            features[:, :, i] = self.extract_feature_win(x)\n",
    "\n",
    "        if self.normalization:\n",
    "            features = (features - self.feat_mean[:, :, np.newaxis]) / self.feat_std[:, :, np.newaxis]\n",
    "\n",
    "        if features.shape[2] > feat_exclude:\n",
    "            features = features[:, :, feat_exclude-1:]  # <-- FIXED HERE\n",
    "        return features\n",
    "\n",
    "\n",
    "    def extract_tail_features(self, feat_num, win_size=600, win_step=120):\n",
    "        n_samples = win_size + (feat_num - 1) * win_step\n",
    "        if self.buffer.shape[1] < n_samples:\n",
    "            return None\n",
    "\n",
    "        buf = self.buffer[:, -n_samples:]\n",
    "        buf = lfilter(self.filter_b, self.filter_a, buf, axis=1)\n",
    "\n",
    "        nch, len_x = buf.shape\n",
    "        n_steps = (len_x - win_size) // win_step + 1\n",
    "        features = np.zeros((nch, 14, n_steps))\n",
    "\n",
    "        for i in range(n_steps):\n",
    "            x = buf[:, i*win_step:i*win_step+win_size]\n",
    "            features[:, :, i] = self.extract_feature_win(x)\n",
    "\n",
    "        features = (features - self.feat_mean[:, :, np.newaxis]) / self.feat_std[:, :, np.newaxis]\n",
    "        return features\n",
    "\n",
    "\n",
    "    def filter_features(self, features):\n",
    "        reshaped = features.reshape(features.shape[0]*features.shape[1], -1).T\n",
    "        pca = PCA(n_components=1)\n",
    "        pcomp = pca.fit_transform(reshaped).squeeze()\n",
    "        pcomp = (pcomp - np.mean(pcomp)) / np.std(pcomp)\n",
    "        med = medfilt(pcomp, kernel_size=5)\n",
    "\n",
    "        if np.mean(med[:40]) > 0:\n",
    "            med = -med\n",
    "\n",
    "        # RMS envelope approximation\n",
    "        window_size = 3\n",
    "        rms_env = np.sqrt(np.convolve(med**2, np.ones(window_size)/window_size, mode='same'))\n",
    "        med = (med - rms_env) - 0.5\n",
    "        return med\n",
    "\n",
    "\n",
    "    def extract_feature_win(self, x):\n",
    "        len_x = x.shape[1]\n",
    "        sum_x = np.sum(x, axis=1)\n",
    "        mean_x = sum_x / len_x\n",
    "        ssq_x = np.sum(x**2, axis=1)\n",
    "        std_x = np.sqrt((ssq_x - 2*sum_x*mean_x + len_x*mean_x**2)/(len_x-1))\n",
    "        diff_x = np.diff(x, axis=1)\n",
    "\n",
    "        zc = np.mean(np.sign(x[:,1:]) != np.sign(x[:,:-1]), axis=1)\n",
    "        ssc = np.mean(np.sign(diff_x[:,1:]) != np.sign(diff_x[:,:-1]), axis=1)\n",
    "        wl = np.mean(np.abs(diff_x), axis=1)\n",
    "        wamp = np.mean(np.abs(np.diff(x, axis=1)) > std_x[:, np.newaxis], axis=1)\n",
    "        mab = np.mean(np.abs(x), axis=1)\n",
    "        msq = ssq_x / len_x\n",
    "        rms = np.sqrt(msq)\n",
    "        v3 = np.cbrt(np.mean(x**3, axis=1))\n",
    "        lgdec = np.exp(np.mean(np.log(np.abs(x) + 1), axis=1))\n",
    "        dabs = np.sqrt(np.mean(diff_x**2, axis=1))\n",
    "        mfl = np.log(np.sqrt(np.mean(diff_x**2, axis=1)) + 1)\n",
    "        mpr = np.mean(x > std_x[:, np.newaxis], axis=1)\n",
    "        mid = x.shape[1] // 2\n",
    "        mavs = np.mean(np.abs(x[:, mid:]), axis=1) - np.mean(np.abs(x[:, :mid]), axis=1)\n",
    "\n",
    "        weight = np.ones_like(x)\n",
    "        weight[:, :int(0.25*len_x)] = 0.5\n",
    "        weight[:, int(0.75*len_x):] = 0.5\n",
    "        wmab = np.mean(weight * np.abs(x), axis=1)\n",
    "\n",
    "        return np.stack([zc, ssc, wl, wamp, mab, msq, rms, v3, lgdec, dabs, mfl, mpr, mavs, wmab], axis=1)\n",
    "\n",
    "from scipy.signal import cheby2\n",
    "\n",
    "def create_cheby2_bandpass(fs, low_cutoff, high_cutoff, order=4, rs=30):\n",
    "    nyq = fs / 2\n",
    "    low = max(1, low_cutoff) / nyq\n",
    "    high = min(0.99 * fs / 2, high_cutoff) / nyq\n",
    "    b, a = cheby2(order, rs, [low, high], btype='bandpass')\n",
    "    return b, a\n",
    "\n",
    "#filter_b, filter_a = create_cheby2_bandpass(fs, lower_cutoff, upper_cutoff)"
   ],
   "id": "69e927f9ac90a808",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T17:17:34.835363Z",
     "start_time": "2025-07-09T17:17:34.832175Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f8a48a6abfc823e2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T17:58:44.013973Z",
     "start_time": "2025-07-09T17:58:43.690900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fs = round(10e6 / 2048)  # 4883 Hz\n",
    "lower_cutoff = 100\n",
    "upper_cutoff = 600\n",
    "filter_b, filter_a = cheby2(4, 30, [lower_cutoff / (fs/2), upper_cutoff / (fs/2)], btype='bandpass')\n",
    "\n",
    "feat_mean_1ch = np.array([0.1, 0.1, 2.5, 0.0, 11.0, 229.0, 13.8, -11.0, 9.0, 3.0, 1.5, 0.0, 0.0, 2.8])\n",
    "feat_std_1ch = np.array([0.02, 0.05, 0.65, 0.02, 4.43, 303.9, 6.85, 12.18, 2.87, 0.87, 0.21, 0.04, 6.68, 1.12])\n",
    "\n",
    "# 정규화 정보\n",
    "feat_mean = np.tile(feat_mean_1ch, (4, 1))\n",
    "feat_std = np.tile(feat_std_1ch, (4, 1))\n",
    "\n",
    "extractor = EMGFeatureExtractor(feat_mean, feat_std, filter_b, filter_a)\n",
    "\n",
    "path = 'C:/Users/hml76/OneDrive/문서/MATLAB/Data_Hunmin/Exp_2025-07-02-v4/E9AD0E7DCC2B/raw/1/'\n",
    "mat = scipy.io.loadmat(path+'Data_20250702_141831.mat')\n",
    "raw_emg_data = mat['Data_ADC']\n",
    "extractor.buffer = raw_emg_data  # shape: (4, 215040)\n",
    "\n",
    "features = extractor.extract_features()\n",
    "print(features.shape)  # → (4, 14, 1787)"
   ],
   "id": "ed7e8810b465dae2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 14, 1729)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "features",
   "id": "96ad141e831fbbb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1cde060524022361"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T21:27:22.137787Z",
     "start_time": "2025-07-08T21:27:22.134582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_info = config.dataset_sub_H\n",
    "\n",
    "\n",
    "\n",
    "feature_set, labels = get_dataset(path, classes, show_labels=False)\n",
    "X_train, y_train, X_test, y_test = utils.split_data(feature_set, labels, ratio=train_ratio)"
   ],
   "id": "3d789a9217e94dc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fd498775888dc866"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c09688716633d487"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "42f9c9ec5bd8e9ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f0e04b58a340454"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "df325c57cdcb08c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fdf0dfe29349e0f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "99738376c25eff0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9c15e3b0ad9ab099"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_dataset(path, classes, show_labels):\n",
    "    for c_idx, c in enumerate(classes):\n",
    "        raw_data = os.listdir(path+c)\n",
    "        if len(raw_data) == 1:\n",
    "            mat = scipy.io.loadmat(path+c+raw_data[0])\n",
    "        else:\n",
    "            print(f\"There is more than one dataset - check - {path} - {classes}\")\n",
    "\n",
    "        if c_idx == 0:\n",
    "            #print(f\"Import matlab raw dataset - Matlab file Keys: {mat.keys()}\")\n",
    "            pass\n",
    "\n",
    "\n",
    "        if c_idx == 0:\n",
    "            feature_set = np.transpose(mat['Data_ADC'], (2, 0, 1))  # shape: (1729, 4, 14)\n",
    "            labels = mat['Data_Cls'].flatten()  #0 or class (either one)\n",
    "\n",
    "        elif c_idx > 0:\n",
    "            feature_set_added = np.transpose(mat['Data_ADC'], (2, 0, 1))\n",
    "            labels_addend = mat['Data_Cls'].flatten()  #0 or class (either one)\n",
    "\n",
    "            feature_set = np.concatenate([feature_set, feature_set_added], axis=0)\n",
    "            labels = np.concatenate([labels, labels_addend], axis=0)\n",
    "        else:\n",
    "            print(\"Error in c_idx\")\n",
    "            break\n",
    "\n",
    "    return feature_set, labels"
   ],
   "id": "1984901fbefedfae"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-08T20:36:44.217055Z",
     "start_time": "2025-07-08T20:36:44.210824Z"
    }
   },
   "source": [
    "def get_dataset(path, classes, show_labels):\n",
    "    for c_idx, c in enumerate(classes):\n",
    "        raw_data = os.listdir(path+c)\n",
    "        if len(raw_data) == 1:\n",
    "            mat = scipy.io.loadmat(path+c+raw_data[0])\n",
    "        else:\n",
    "            print(f\"There is more than one dataset - check - {path} - {classes}\")\n",
    "\n",
    "        if c_idx == 0:\n",
    "            #print(f\"Import matlab raw dataset - Matlab file Keys: {mat.keys()}\")\n",
    "            pass\n",
    "\n",
    "        if mat['Data_Cls'].shape[-1] != mat['Data_ADC'].shape[-1]:\n",
    "            print(f\"Label and dataset do not match! : {len(mat['Data_Cls'])}, {len(mat['Data_Fea'])}\")\n",
    "            break\n",
    "\n",
    "        if c_idx == 0:\n",
    "            feature_set = np.transpose(mat['Data_ADC'], (2, 0, 1))  # shape: (1729, 4, 14)\n",
    "            labels = mat['Data_Cls'].flatten()  #0 or class (either one)\n",
    "\n",
    "        elif c_idx > 0:\n",
    "            feature_set_added = np.transpose(mat['Data_ADC'], (2, 0, 1))\n",
    "            labels_addend = mat['Data_Cls'].flatten()  #0 or class (either one)\n",
    "\n",
    "            feature_set = np.concatenate([feature_set, feature_set_added], axis=0)\n",
    "            labels = np.concatenate([labels, labels_addend], axis=0)\n",
    "        else:\n",
    "            print(\"Error in c_idx\")\n",
    "            break\n",
    "\n",
    "    if show_labels:\n",
    "        plt.figure(figsize=(8,3))\n",
    "        plt.plot(labels)\n",
    "        plt.ylabel('Class label', fontsize=13)\n",
    "        plt.xlabel('Samples', fontsize=13)\n",
    "        plt.grid(True, which='both', linestyle='--')\n",
    "        plt.show()\n",
    "\n",
    "    return feature_set, labels"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "232633d33767c5b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5b4669bb8fc572e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6a51b20a5be8e8df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T20:37:27.107602Z",
     "start_time": "2025-07-08T20:37:27.102176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "default_path = config.default_path_sub_H\n",
    "dataset_info = config.dataset_sub_H\n",
    "\n",
    "path = os.path.join(default_path, f'{session_info}/raw/')\n",
    "\n",
    "feature_set, labels = get_dataset(path, classes, show_labels=False)\n",
    "X_train, y_train, X_test, y_test = utils.split_data(feature_set, labels, ratio=train_ratio)"
   ],
   "id": "af84b2cd18bca831",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/hml76/OneDrive/문서/MATLAB/Data_Hunmin/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6881c403c295efb4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
